{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c850ef-84e0-4082-8285-c14dffb801b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Dataset\n",
    "\n",
    "import optuna\n",
    "from metrics import metrics_from_preds\n",
    "from preprocess import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cf8a64e-f46f-4b69-8d17-7bf10c68529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Para reproducibilidad estricta; si alguna op no soporta determinismo, solo avisa.\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5298d0-d82e-425d-98c2-0671ffeff358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# Forzamos CPU para bit-a-bit. (Si luego quieres GPU, cambia a 'cuda' sabiendo que habrá\n",
    "# pequeñas variaciones numéricas.)\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Usando dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5440f63-83e0-4e2f-b1a2-73d280dd9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_training, labels_training, vids_val, labels_val, vids_test, labels_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f311b753-3bcd-4069-b8d2-db64a7a7d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    \"\"\"Envuelve listas de (video, label).\n",
    "       Espera 'video' con shape (T, F). Devuelve (x: Tensor[T, F], y: LongTensor[]).\"\"\"\n",
    "    def __init__(self, videos, labels):\n",
    "        self.videos = videos\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(np.array(self.videos[idx]), dtype=torch.float32)  # (T, F)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)               # ()\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1401ac0-cf52-4610-b292-a925c729e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_pad(batch):\n",
    "    \"\"\"Collate simple asumiendo T fijo en el dataset (sin padding).\"\"\"\n",
    "    xs, ys = zip(*batch)\n",
    "    x = torch.stack(xs, dim=0)  # (B, T, F)\n",
    "    y = torch.stack(ys, dim=0)  # (B,)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb74413-5ae7-4dc1-b438-1ae54e9786c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c27f53-7581-49b9-bfd5-04f76b2e404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VideoDataset(vids_training, labels_training)\n",
    "val_dataset   = VideoDataset(vids_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fad0710-5776-43e6-aa97-b09c5628e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "perm = torch.randperm(len(train_dataset), generator=g).tolist()\n",
    "train_sampler = SubsetRandomSampler(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314eb590-7974-4b11-9bf2-27449964f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_seq = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=False, sampler=train_sampler,\n",
    "    num_workers=0, collate_fn=collate_pad\n",
    ")\n",
    "val_loader_seq = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False,\n",
    "    num_workers=0, collate_fn=collate_pad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5245a60-5daa-4628-a54d-b85244285971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3, dilation=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        pad = (kernel_size - 1) * dilation // 2  # 'same' padding aproximado\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size, padding=pad, dilation=dilation)\n",
    "        self.norm = nn.BatchNorm1d(out_ch)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.act  = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):  # x: (B, C, T)\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class MSTCN(nn.Module):\n",
    "    \"\"\"MS-TCN para clasificación de secuencias:\n",
    "       Entrada:  (B, T, F)\n",
    "       Conv1d:   (B, F, T)\n",
    "       Capas:    'layers' bloques con dilaciones 1,2,4,...\n",
    "       Salida:   (B, num_classes)\"\"\"\n",
    "    def __init__(self, in_feat=258, hidden=128, layers=3, dropout=0.1, kernel_size=3, num_classes=4):\n",
    "        super().__init__()\n",
    "        stages = []\n",
    "        in_ch = in_feat\n",
    "        for i in range(layers):\n",
    "            d = 2 ** i\n",
    "            stages.append(TemporalBlock(in_ch, hidden, kernel_size=kernel_size, dilation=d, dropout=dropout))\n",
    "            in_ch = hidden\n",
    "        self.stages = nn.ModuleList(stages)\n",
    "        self.head = nn.Linear(hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):          # x: (B, T, F)\n",
    "        x = x.transpose(1, 2)      # -> (B, F, T)\n",
    "        for blk in self.stages:\n",
    "            x = blk(x)             # (B, hidden, T)\n",
    "        x = x.mean(dim=-1)         # GAP en T -> (B, hidden)\n",
    "        return self.head(x)        # (B, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c69cff2c-f2ac-411a-8272-42d50e245955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_ms_tcn(train_loader_seq, val_loader_seq, n_trials=10, max_epochs=50, save_prefix=\"hpo_ms_tcn\"):\n",
    "    set_seed(42)  # semilla global fija para el estudio\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler,\n",
    "                                pruner=optuna.pruners.MedianPruner())\n",
    "    all_trials = []\n",
    "\n",
    "    # Detectar automáticamente F (número de features)\n",
    "    sample_x, _ = next(iter(train_loader_seq))\n",
    "    in_feat = sample_x.shape[-1]\n",
    "\n",
    "    def objective(trial):\n",
    "        hidden  = trial.suggest_categorical(\"hidden\", [96, 128, 160, 192])\n",
    "        layers  = trial.suggest_int(\"layers\", 2, 5)\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "        ksz     = trial.suggest_categorical(\"kernel_size\", [3, 5, 7])\n",
    "        lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "        wd      = trial.suggest_float(\"weight_decay\", 1e-10, 1e-3, log=True)\n",
    "\n",
    "        model = MSTCN(in_feat=in_feat, hidden=hidden, layers=layers,\n",
    "                      dropout=dropout, kernel_size=ksz, num_classes=4).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        best_val = 0.0\n",
    "        for epoch in range(max_epochs):\n",
    "            # --- Train ---\n",
    "            model.train()\n",
    "            for xb, yb in train_loader_seq:\n",
    "                xb = xb.to(device); yb = yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # --- Validation ---\n",
    "            model.eval()\n",
    "            y_true, y_pred = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader_seq:\n",
    "                    xb = xb.to(device)\n",
    "                    preds = model(xb).argmax(dim=1)\n",
    "                    y_true.extend(yb.numpy())\n",
    "                    y_pred.extend(preds.cpu().numpy())\n",
    "            val_acc = metrics_from_preds(y_true, y_pred)[\"accuracy\"]\n",
    "\n",
    "            if val_acc > best_val:\n",
    "                best_val = val_acc\n",
    "\n",
    "            trial.report(val_acc, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "        all_trials.append({\"trial\": trial.number, \"params\": trial.params, \"best_val_acc\": best_val})\n",
    "        return best_val\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    # Guardar resultados\n",
    "    with open(f\"{save_prefix}_all.json\", \"w\") as f:\n",
    "        json.dump(all_trials, f, indent=2)\n",
    "    with open(f\"{save_prefix}_best.json\", \"w\") as f:\n",
    "        json.dump({\"best_params\": study.best_params, \"best_value\": study.best_value}, f, indent=2)\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfe2d91a-5451-4ebb-94d5-6a582d128e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-04 11:06:16,958] A new study created in memory with name: no-name-8abe7684-61c0-4170-84ef-7ea87efa1903\n",
      "[I 2025-11-04 11:06:43,637] Trial 0 finished with value: 0.9277777777777778 and parameters: {'hidden': 128, 'layers': 2, 'dropout': 0.07799726016810132, 'kernel_size': 5, 'lr': 0.0013035123791853842, 'weight_decay': 1.3934502251337584e-10}. Best is trial 0 with value: 0.9277777777777778.\n",
      "[I 2025-11-04 11:07:01,439] Trial 1 finished with value: 0.9055555555555556 and parameters: {'hidden': 96, 'layers': 2, 'dropout': 0.15212112147976886, 'kernel_size': 3, 'lr': 0.0008369042894376068, 'weight_decay': 9.472334467618544e-10}. Best is trial 0 with value: 0.9277777777777778.\n",
      "[I 2025-11-04 11:08:00,684] Trial 2 finished with value: 0.9055555555555556 and parameters: {'hidden': 192, 'layers': 2, 'dropout': 0.2571172192068058, 'kernel_size': 7, 'lr': 0.0001096524277832185, 'weight_decay': 2.853390105240223e-10}. Best is trial 0 with value: 0.9277777777777778.\n",
      "[I 2025-11-04 11:08:36,716] Trial 3 finished with value: 0.9277777777777778 and parameters: {'hidden': 128, 'layers': 2, 'dropout': 0.34211651325607845, 'kernel_size': 7, 'lr': 5.8579686961535335e-05, 'weight_decay': 0.0002318690670290197}. Best is trial 0 with value: 0.9277777777777778.\n",
      "[I 2025-11-04 11:09:15,328] Trial 4 finished with value: 0.9277777777777778 and parameters: {'hidden': 128, 'layers': 4, 'dropout': 0.09242722776276352, 'kernel_size': 3, 'lr': 0.0030805247696904818, 'weight_decay': 1.5321449415450716e-06}. Best is trial 0 with value: 0.9277777777777778.\n",
      "[I 2025-11-04 11:09:15,905] Trial 5 pruned. \n",
      "[I 2025-11-04 11:09:24,500] Trial 6 pruned. \n",
      "[I 2025-11-04 11:09:26,649] Trial 7 pruned. \n",
      "[I 2025-11-04 11:09:27,369] Trial 8 pruned. \n",
      "[I 2025-11-04 11:09:29,295] Trial 9 pruned. \n",
      "[I 2025-11-04 11:09:30,070] Trial 10 pruned. \n",
      "[I 2025-11-04 11:09:32,328] Trial 11 pruned. \n",
      "[I 2025-11-04 11:09:33,324] Trial 12 pruned. \n",
      "[I 2025-11-04 11:09:33,907] Trial 13 pruned. \n",
      "[I 2025-11-04 11:09:34,812] Trial 14 pruned. \n",
      "[I 2025-11-04 11:10:13,349] Trial 15 finished with value: 0.9277777777777778 and parameters: {'hidden': 128, 'layers': 3, 'dropout': 0.012774747405271514, 'kernel_size': 5, 'lr': 0.00030643028014644283, 'weight_decay': 3.161263877458707e-05}. Best is trial 0 with value: 0.9277777777777778.\n",
      "[I 2025-11-04 11:10:14,116] Trial 16 pruned. \n",
      "[I 2025-11-04 11:10:18,448] Trial 17 pruned. \n",
      "[I 2025-11-04 11:10:19,158] Trial 18 pruned. \n",
      "[I 2025-11-04 11:10:28,089] Trial 19 pruned. \n",
      "[I 2025-11-04 11:10:28,663] Trial 20 pruned. \n",
      "[I 2025-11-04 11:11:10,578] Trial 21 finished with value: 0.9333333333333333 and parameters: {'hidden': 128, 'layers': 4, 'dropout': 0.09840922498488261, 'kernel_size': 3, 'lr': 0.0032356080020134906, 'weight_decay': 0.000102281458387574}. Best is trial 21 with value: 0.9333333333333333.\n",
      "[I 2025-11-04 11:11:11,385] Trial 22 pruned. \n",
      "[I 2025-11-04 11:11:12,218] Trial 23 pruned. \n",
      "[I 2025-11-04 11:11:12,970] Trial 24 pruned. \n",
      "[I 2025-11-04 11:11:13,902] Trial 25 pruned. \n",
      "[I 2025-11-04 11:11:19,410] Trial 26 pruned. \n",
      "[I 2025-11-04 11:11:21,426] Trial 27 pruned. \n",
      "[I 2025-11-04 11:11:24,034] Trial 28 pruned. \n",
      "[I 2025-11-04 11:11:48,400] Trial 29 finished with value: 0.9 and parameters: {'hidden': 96, 'layers': 2, 'dropout': 0.18032226206400184, 'kernel_size': 5, 'lr': 0.0007225289913004433, 'weight_decay': 2.582868760193832e-09}. Best is trial 21 with value: 0.9333333333333333.\n",
      "[I 2025-11-04 11:11:52,203] Trial 30 pruned. \n",
      "[I 2025-11-04 11:11:52,907] Trial 31 pruned. \n",
      "[I 2025-11-04 11:11:53,617] Trial 32 pruned. \n",
      "[I 2025-11-04 11:11:54,320] Trial 33 pruned. \n",
      "[I 2025-11-04 11:11:55,524] Trial 34 pruned. \n",
      "[I 2025-11-04 11:11:57,190] Trial 35 pruned. \n",
      "[I 2025-11-04 11:11:57,881] Trial 36 pruned. \n",
      "[I 2025-11-04 11:11:58,800] Trial 37 pruned. \n",
      "[I 2025-11-04 11:12:00,051] Trial 38 pruned. \n",
      "[I 2025-11-04 11:12:00,918] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado: 0.9333333333333333\n",
      "Mejores hiperparámetros: {'hidden': 128, 'layers': 4, 'dropout': 0.09840922498488261, 'kernel_size': 3, 'lr': 0.0032356080020134906, 'weight_decay': 0.000102281458387574}\n",
      "Epoch 001 | Val Acc: 0.6500\n",
      "Epoch 002 | Val Acc: 0.7278\n",
      "Epoch 003 | Val Acc: 0.8167\n",
      "Epoch 004 | Val Acc: 0.8667\n",
      "Epoch 005 | Val Acc: 0.8611\n",
      "Epoch 006 | Val Acc: 0.5722\n",
      "Epoch 007 | Val Acc: 0.7722\n",
      "Epoch 008 | Val Acc: 0.7778\n",
      "Epoch 009 | Val Acc: 0.7167\n",
      "Epoch 010 | Val Acc: 0.7111\n",
      "Epoch 011 | Val Acc: 0.8667\n",
      "Epoch 012 | Val Acc: 0.7778\n",
      "Epoch 013 | Val Acc: 0.7556\n",
      "Epoch 014 | Val Acc: 0.8278\n",
      "Epoch 015 | Val Acc: 0.8444\n",
      "Epoch 016 | Val Acc: 0.9167\n",
      "Epoch 017 | Val Acc: 0.6722\n",
      "Epoch 018 | Val Acc: 0.8056\n",
      "Epoch 019 | Val Acc: 0.8167\n",
      "Epoch 020 | Val Acc: 0.8889\n",
      "Epoch 021 | Val Acc: 0.8889\n",
      "Epoch 022 | Val Acc: 0.8889\n",
      "Epoch 023 | Val Acc: 0.8556\n",
      "Epoch 024 | Val Acc: 0.8611\n",
      "Epoch 025 | Val Acc: 0.7444\n",
      "Epoch 026 | Val Acc: 0.7944\n",
      "Epoch 027 | Val Acc: 0.7722\n",
      "Epoch 028 | Val Acc: 0.9111\n",
      "Epoch 029 | Val Acc: 0.8667\n",
      "Epoch 030 | Val Acc: 0.8000\n",
      "Epoch 031 | Val Acc: 0.8444\n",
      "Epoch 032 | Val Acc: 0.9389\n",
      "Epoch 033 | Val Acc: 0.8667\n",
      "Epoch 034 | Val Acc: 0.9111\n",
      "Epoch 035 | Val Acc: 0.8722\n",
      "Epoch 036 | Val Acc: 0.8833\n",
      "Epoch 037 | Val Acc: 0.8389\n",
      "Epoch 038 | Val Acc: 0.9167\n",
      "Epoch 039 | Val Acc: 0.8278\n",
      "Epoch 040 | Val Acc: 0.8167\n",
      "Epoch 041 | Val Acc: 0.8944\n",
      "Epoch 042 | Val Acc: 0.9111\n",
      "Epoch 043 | Val Acc: 0.8056\n",
      "Epoch 044 | Val Acc: 0.8500\n",
      "Epoch 045 | Val Acc: 0.9111\n",
      "Epoch 046 | Val Acc: 0.9222\n",
      "Epoch 047 | Val Acc: 0.9000\n",
      "Epoch 048 | Val Acc: 0.8833\n",
      "Epoch 049 | Val Acc: 0.9167\n",
      "Epoch 050 | Val Acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study_ms_tcn = optimize_ms_tcn(train_loader_seq, val_loader_seq, n_trials=40, max_epochs=50)\n",
    "    print(\"Mejor resultado:\", study_ms_tcn.best_value)\n",
    "    print(\"Mejores hiperparámetros:\", study_ms_tcn.best_params)\n",
    "\n",
    "    # =============================================================================\n",
    "    # [9] Reentrenar el mejor modelo de forma 100% reproducible\n",
    "    # =============================================================================\n",
    "    best = study_ms_tcn.best_params\n",
    "    set_seed(42)  # entrenamiento único reproducible\n",
    "\n",
    "    # Recuperar in_feat\n",
    "    sample_x, _ = next(iter(train_loader_seq))\n",
    "    in_feat = sample_x.shape[-1]\n",
    "\n",
    "    model = MSTCN(\n",
    "        in_feat=in_feat,\n",
    "        hidden=best[\"hidden\"],\n",
    "        layers=best[\"layers\"],\n",
    "        dropout=best[\"dropout\"],\n",
    "        kernel_size=best[\"kernel_size\"],\n",
    "        num_classes=4\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=best[\"lr\"], weight_decay=best[\"weight_decay\"])\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader_seq:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader_seq:\n",
    "                xb = xb.to(device)\n",
    "                preds = model(xb).argmax(dim=1)\n",
    "                y_true.extend(yb.numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "        val_acc = metrics_from_preds(y_true, y_pred)[\"accuracy\"]\n",
    "        print(f\"Epoch {epoch+1:03d} | Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e7fdc-8268-4038-a87c-b142948f2221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
