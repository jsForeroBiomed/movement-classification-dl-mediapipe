{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41868ed-50f1-451d-8a9e-de339562f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "\n",
    "import optuna\n",
    "from metrics import metrics_from_preds\n",
    "from preprocess import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaaedc7-1beb-466d-b2f3-0b3ee4c02f9c",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac58d429-b25a-4d48-85ae-9e187efd4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    SEED = seed\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f74ce88-c202-4b6c-b05c-0e8f1cd0ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483c2a4f-f4bb-41ab-bdd8-32697054d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe0935f-e427-42a0-a2bf-96d72fbc2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_training, labels_training, vids_val, labels_val, vids_test, labels_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64dbffe7-fec1-49f4-a1a7-85a1c83fb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, videos, labels):\n",
    "        self.videos = videos\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(np.array(self.videos[idx]), dtype=torch.float32)  # (16, 258)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50053d9c-0335-4ee9-85d7-c1da21e2fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "train_dataset = VideoDataset(vids_training, labels_training)\n",
    "val_dataset   = VideoDataset(vids_val, labels_val)\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "perm = torch.randperm(len(train_dataset), generator=g).tolist()\n",
    "train_sampler = SubsetRandomSampler(perm)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=0, sampler=train_sampler)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a6d8e-649c-461d-8641-a220be360a2a",
   "metadata": {},
   "source": [
    "# Modelo TGU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97d3f98-cc01-493d-950c-7f7a3141fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGUBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.conv_filter = nn.Conv1d(in_channels, out_channels, kernel_size, padding=1)\n",
    "        self.conv_gate   = nn.Conv1d(in_channels, out_channels, kernel_size, padding=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        f = torch.tanh(self.conv_filter(x))\n",
    "        g = torch.sigmoid(self.conv_gate(x))\n",
    "        return self.dropout(f * g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d783ca-bb45-4c7a-b805-b21e314d28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGUModel(nn.Module):\n",
    "    def __init__(self, in_features=258, num_classes=4, hidden=128, layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(TGUBlock(in_features, hidden, dropout=dropout))\n",
    "        for _ in range(layers - 1):\n",
    "            self.layers.append(TGUBlock(hidden, hidden, dropout=dropout))\n",
    "        self.head = nn.Linear(hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Entrada: (B, 16, 258)\n",
    "        x = x.transpose(1, 2)     # (B, 258, 16)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)          # (B, hidden, L)\n",
    "        x = x.mean(dim=2)         # pooling temporal -> (B, hidden)\n",
    "        return self.head(x)       # logits (B, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c099a11-add6-4dc4-a8fe-22d051f555d9",
   "metadata": {},
   "source": [
    "# Optimización de Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9c36c0a-f916-4945-81fa-9a3440515108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tgu(train_loader, val_loader, n_trials=50, max_epochs=80, save_prefix=\"hpo_tgu\"):\n",
    "    set_seed()\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    all_trials = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def objective(trial):\n",
    "        hidden  = trial.suggest_categorical(\"hidden\",[96,128,160,192])\n",
    "        layers  = trial.suggest_int(\"layers\", 2, 5)\n",
    "        drop    = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "        lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "        wd      = trial.suggest_float(\"weight_decay\", 1e-10, 1e-3, log=True)\n",
    "\n",
    "        model = TGUModel(hidden=hidden, layers=layers, dropout=drop).to(device)\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "        opt  = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        best_val = 0.0\n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                opt.zero_grad()\n",
    "                out = model(X)\n",
    "                loss = crit(out, y)\n",
    "                loss.backward(); opt.step()\n",
    "            # val\n",
    "            model.eval()\n",
    "            y_true, y_pred = [], []\n",
    "            with torch.no_grad():\n",
    "                for X, y in val_loader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    pred = model(X).argmax(1)\n",
    "                    y_true.extend(y.cpu().numpy()); y_pred.extend(pred.cpu().numpy())\n",
    "            val_acc = metrics_from_preds(y_true, y_pred)[\"accuracy\"]\n",
    "            if val_acc > best_val: best_val = val_acc\n",
    "            trial.report(val_acc, epoch)\n",
    "            if trial.should_prune(): raise optuna.TrialPruned()\n",
    "\n",
    "        all_trials.append({\"trial\": trial.number, \"params\": trial.params, \"best_val_acc\": best_val})\n",
    "        return best_val\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    with open(f\"{save_prefix}_all.json\",\"w\") as f: json.dump(all_trials,f,indent=2)\n",
    "    with open(f\"{save_prefix}_best.json\",\"w\") as f: json.dump({\"best_params\":study.best_params,\n",
    "                                                               \"best_value\":study.best_value},\n",
    "                                                              f,\n",
    "                                                              indent=2)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55d4503a-677c-4e89-b19a-ba7c8f1385a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 12:33:35,643] A new study created in memory with name: no-name-2ad10dae-b530-4f53-b28c-93e6d8a8a801\n",
      "[I 2025-11-03 12:34:57,215] Trial 0 finished with value: 0.9166666666666666 and parameters: {'hidden': 160, 'layers': 3, 'dropout': 0.0890957647258876, 'lr': 0.0020060497235614427, 'weight_decay': 5.899658082360121e-07}. Best is trial 0 with value: 0.9166666666666666.\n",
      "[I 2025-11-03 12:36:25,890] Trial 1 finished with value: 0.8833333333333333 and parameters: {'hidden': 160, 'layers': 3, 'dropout': 0.2483083605070005, 'lr': 0.00015099792322190343, 'weight_decay': 1.080547961002526e-06}. Best is trial 0 with value: 0.9166666666666666.\n",
      "[I 2025-11-03 12:37:19,037] Trial 2 finished with value: 0.8888888888888888 and parameters: {'hidden': 96, 'layers': 3, 'dropout': 0.34160507205086277, 'lr': 0.0035326640245268385, 'weight_decay': 0.00025977813763728444}. Best is trial 0 with value: 0.9166666666666666.\n",
      "[I 2025-11-03 12:39:45,772] Trial 3 finished with value: 0.8888888888888888 and parameters: {'hidden': 160, 'layers': 5, 'dropout': 0.005160085426787697, 'lr': 0.0015538591977517868, 'weight_decay': 2.6977098712258567e-09}. Best is trial 0 with value: 0.9166666666666666.\n",
      "[I 2025-11-03 12:41:03,864] Trial 4 finished with value: 0.8833333333333333 and parameters: {'hidden': 128, 'layers': 3, 'dropout': 0.09752887975178431, 'lr': 0.0019085419015450196, 'weight_decay': 3.1055057882513297e-10}. Best is trial 0 with value: 0.9166666666666666.\n",
      "[I 2025-11-03 12:41:04,694] Trial 5 pruned. \n",
      "[I 2025-11-03 12:41:07,412] Trial 6 pruned. \n",
      "[I 2025-11-03 12:41:08,094] Trial 7 pruned. \n",
      "[I 2025-11-03 12:41:08,647] Trial 8 pruned. \n",
      "[I 2025-11-03 12:41:10,780] Trial 9 pruned. \n",
      "[I 2025-11-03 12:41:11,396] Trial 10 pruned. \n",
      "[I 2025-11-03 12:41:12,378] Trial 11 pruned. \n",
      "[I 2025-11-03 12:41:12,773] Trial 12 pruned. \n",
      "[I 2025-11-03 12:41:16,624] Trial 13 pruned. \n",
      "[I 2025-11-03 12:41:18,870] Trial 14 pruned. \n",
      "[I 2025-11-03 12:41:19,564] Trial 15 pruned. \n",
      "[I 2025-11-03 12:41:21,895] Trial 16 pruned. \n",
      "[I 2025-11-03 12:41:24,369] Trial 17 pruned. \n",
      "[I 2025-11-03 12:41:25,137] Trial 18 pruned. \n",
      "[I 2025-11-03 12:42:32,312] Trial 19 finished with value: 0.9111111111111111 and parameters: {'hidden': 160, 'layers': 2, 'dropout': 0.2748368610235535, 'lr': 0.0029859103608198025, 'weight_decay': 2.869463673068743e-06}. Best is trial 0 with value: 0.9166666666666666.\n",
      "[I 2025-11-03 12:42:33,020] Trial 20 pruned. \n",
      "[I 2025-11-03 12:42:33,721] Trial 21 pruned. \n",
      "[I 2025-11-03 12:42:35,613] Trial 22 pruned. \n",
      "[I 2025-11-03 12:42:48,503] Trial 23 pruned. \n",
      "[I 2025-11-03 12:43:01,372] Trial 24 pruned. \n",
      "[I 2025-11-03 12:43:01,881] Trial 25 pruned. \n",
      "[I 2025-11-03 12:43:12,914] Trial 26 pruned. \n",
      "[I 2025-11-03 12:43:35,140] Trial 27 pruned. \n",
      "[I 2025-11-03 12:43:36,149] Trial 28 pruned. \n",
      "[I 2025-11-03 12:43:37,722] Trial 29 pruned. \n",
      "[I 2025-11-03 12:43:38,551] Trial 30 pruned. \n",
      "[I 2025-11-03 12:44:15,959] Trial 31 pruned. \n",
      "[I 2025-11-03 12:44:20,168] Trial 32 pruned. \n",
      "[I 2025-11-03 12:44:21,446] Trial 33 pruned. \n",
      "[I 2025-11-03 12:44:38,880] Trial 34 pruned. \n",
      "[I 2025-11-03 12:44:39,985] Trial 35 pruned. \n",
      "[I 2025-11-03 12:44:48,829] Trial 36 pruned. \n",
      "[I 2025-11-03 12:45:06,936] Trial 37 pruned. \n",
      "[I 2025-11-03 12:45:07,628] Trial 38 pruned. \n",
      "[I 2025-11-03 12:45:08,196] Trial 39 pruned. \n"
     ]
    }
   ],
   "source": [
    "study_tgu = optimize_tgu(train_loader, val_loader, n_trials=40, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba18852-84e7-46a9-80f5-06d3beee0b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado: 0.9166666666666666\n",
      "Mejores hiperparámetros: {'hidden': 160, 'layers': 3, 'dropout': 0.0890957647258876, 'lr': 0.0020060497235614427, 'weight_decay': 5.899658082360121e-07}\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor resultado:\", study_tgu.best_value)\n",
    "print(\"Mejores hiperparámetros:\", study_tgu.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
