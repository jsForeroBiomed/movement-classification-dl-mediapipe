{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41868ed-50f1-451d-8a9e-de339562f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Dataset\n",
    "\n",
    "import optuna\n",
    "from metrics import metrics_from_preds\n",
    "from preprocess import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04388df3-6195-4ae2-ad27-156f9e71dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5107af-66b0-45f9-b150-9314bd7704f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cpu\")  # para máxima reproducibilidad\n",
    "print(\"Usando dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23471633-6e8a-46e2-a4b4-d59147502c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_training, labels_training, vids_val, labels_val, vids_test, labels_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a4804a-d0c0-4c2e-8ef4-b9ec72eb6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, videos, labels):\n",
    "        self.videos = videos\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(np.array(self.videos[idx]), dtype=torch.float32)  # (T, F)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b635b1-b3a5-4a24-94f7-70f6cd645404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_pad(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    x = torch.stack(xs, dim=0)  # (B, T, F)\n",
    "    y = torch.stack(ys, dim=0)  # (B,)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f088fc73-8203-4ef8-b984-002b72ab5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b384e02-c14d-4a92-8034-76f84efe4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VideoDataset(vids_training, labels_training)\n",
    "val_dataset   = VideoDataset(vids_val, labels_val)\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "perm = torch.randperm(len(train_dataset), generator=g).tolist()\n",
    "train_sampler = SubsetRandomSampler(perm)\n",
    "\n",
    "train_loader_seq = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=False, sampler=train_sampler,\n",
    "    num_workers=0, collate_fn=collate_pad\n",
    ")\n",
    "val_loader_seq = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False,\n",
    "    num_workers=0, collate_fn=collate_pad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba5cb3ff-50ea-4c38-acca-4a66447a15ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Clasificador secuencial basado en LSTM.\n",
    "       Entrada:  (B, T, F)\n",
    "       LSTM:     salida (B, T, hidden)\n",
    "       Pooling:  último paso temporal\n",
    "       Salida:   (B, num_classes)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=258, hidden_size=128, num_layers=2, dropout=0.1, num_classes=4, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        out_dim = hidden_size * (2 if bidirectional else 1)\n",
    "        self.fc = nn.Linear(out_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):  # x: (B, T, F)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # último paso temporal\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c790f33e-2ee3-4b70-8370-996cba26f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_lstm(train_loader_seq, val_loader_seq, n_trials=10, max_epochs=50, save_prefix=\"hpo_lstm\"):\n",
    "    set_seed(42)\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler,\n",
    "                                pruner=optuna.pruners.MedianPruner())\n",
    "    all_trials = []\n",
    "\n",
    "    sample_x, _ = next(iter(train_loader_seq))\n",
    "    input_size = sample_x.shape[-1]\n",
    "\n",
    "    def objective(trial):\n",
    "        hidden  = trial.suggest_categorical(\"hidden_size\", [64, 96, 128, 160, 192])\n",
    "        layers  = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "        bi      = trial.suggest_categorical(\"bidirectional\", [False, True])\n",
    "        lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "        wd      = trial.suggest_float(\"weight_decay\", 1e-10, 1e-3, log=True)\n",
    "\n",
    "        model = LSTMClassifier(\n",
    "            input_size=input_size, hidden_size=hidden, num_layers=layers,\n",
    "            dropout=dropout, num_classes=4, bidirectional=bi\n",
    "        ).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        best_val = 0.0\n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            for xb, yb in train_loader_seq:\n",
    "                xb = xb.to(device); yb = yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            y_true, y_pred = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader_seq:\n",
    "                    xb = xb.to(device)\n",
    "                    preds = model(xb).argmax(dim=1)\n",
    "                    y_true.extend(yb.numpy())\n",
    "                    y_pred.extend(preds.cpu().numpy())\n",
    "            val_acc = metrics_from_preds(y_true, y_pred)[\"accuracy\"]\n",
    "\n",
    "            if val_acc > best_val:\n",
    "                best_val = val_acc\n",
    "\n",
    "            trial.report(val_acc, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "        all_trials.append({\"trial\": trial.number, \"params\": trial.params, \"best_val_acc\": best_val})\n",
    "        return best_val\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    with open(f\"{save_prefix}_all.json\", \"w\") as f:\n",
    "        json.dump(all_trials, f, indent=2)\n",
    "    with open(f\"{save_prefix}_best.json\", \"w\") as f:\n",
    "        json.dump({\"best_params\": study.best_params, \"best_value\": study.best_value}, f, indent=2)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017021bb-b645-440f-a087-e28511e4cd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-04 11:25:26,069] A new study created in memory with name: no-name-d54623d4-3b30-4d80-b2d5-57425c49ee63\n",
      "[I 2025-11-04 11:25:42,084] Trial 0 finished with value: 0.8722222222222222 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.02904180608409973, 'bidirectional': False, 'lr': 0.0013035123791853842, 'weight_decay': 1.3934502251337584e-10}. Best is trial 0 with value: 0.8722222222222222.\n",
      "[I 2025-11-04 11:26:00,521] Trial 1 finished with value: 0.8555555555555555 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2623782158161189, 'bidirectional': False, 'lr': 0.0008369042894376068, 'weight_decay': 9.472334467618544e-10}. Best is trial 0 with value: 0.8722222222222222.\n",
      "[I 2025-11-04 11:29:18,540] Trial 2 finished with value: 0.8611111111111112 and parameters: {'hidden_size': 160, 'num_layers': 3, 'dropout': 0.29620728443102123, 'bidirectional': True, 'lr': 0.0001096524277832185, 'weight_decay': 2.853390105240223e-10}. Best is trial 0 with value: 0.8722222222222222.\n",
      "[I 2025-11-04 11:30:49,119] Trial 3 finished with value: 0.8611111111111112 and parameters: {'hidden_size': 96, 'num_layers': 3, 'dropout': 0.22007624686980065, 'bidirectional': True, 'lr': 5.8579686961535335e-05, 'weight_decay': 0.0002318690670290197}. Best is trial 0 with value: 0.8722222222222222.\n",
      "[I 2025-11-04 11:31:23,484] Trial 4 finished with value: 0.8777777777777778 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.4847923138822793, 'bidirectional': True, 'lr': 0.0030805247696904818, 'weight_decay': 1.5321449415450716e-06}. Best is trial 4 with value: 0.8777777777777778.\n",
      "[I 2025-11-04 11:31:23,836] Trial 5 pruned. \n",
      "[I 2025-11-04 11:31:52,248] Trial 6 finished with value: 0.8944444444444445 and parameters: {'hidden_size': 160, 'num_layers': 1, 'dropout': 0.0027610585618011996, 'bidirectional': False, 'lr': 0.001435437674097734, 'weight_decay': 2.5054885755573557e-05}. Best is trial 6 with value: 0.8944444444444445.\n",
      "[I 2025-11-04 11:31:54,994] Trial 7 pruned. \n",
      "[I 2025-11-04 11:31:55,991] Trial 8 pruned. \n",
      "[I 2025-11-04 11:31:59,434] Trial 9 pruned. \n",
      "[I 2025-11-04 11:32:00,127] Trial 10 pruned. \n",
      "[I 2025-11-04 11:32:00,475] Trial 11 pruned. \n",
      "[I 2025-11-04 11:32:01,034] Trial 12 pruned. \n",
      "[I 2025-11-04 11:32:01,859] Trial 13 pruned. \n",
      "[I 2025-11-04 11:32:04,943] Trial 14 pruned. \n",
      "[I 2025-11-04 11:32:08,440] Trial 15 pruned. \n",
      "[I 2025-11-04 11:32:08,808] Trial 16 pruned. \n",
      "[I 2025-11-04 11:34:11,879] Trial 17 finished with value: 0.8333333333333334 and parameters: {'hidden_size': 160, 'num_layers': 2, 'dropout': 0.31122173984401474, 'bidirectional': True, 'lr': 0.0003293390194243909, 'weight_decay': 9.62903269955436e-07}. Best is trial 6 with value: 0.8944444444444445.\n",
      "[I 2025-11-04 11:34:12,530] Trial 18 pruned. \n",
      "[I 2025-11-04 11:34:13,281] Trial 19 pruned. \n",
      "[I 2025-11-04 11:34:16,048] Trial 20 pruned. \n",
      "[I 2025-11-04 11:34:16,395] Trial 21 pruned. \n",
      "[I 2025-11-04 11:34:17,617] Trial 22 pruned. \n",
      "[I 2025-11-04 11:34:17,980] Trial 23 pruned. \n",
      "[I 2025-11-04 11:34:19,992] Trial 24 pruned. \n",
      "[I 2025-11-04 11:34:20,729] Trial 25 pruned. \n",
      "[I 2025-11-04 11:34:47,053] Trial 26 finished with value: 0.8944444444444445 and parameters: {'hidden_size': 96, 'num_layers': 2, 'dropout': 0.10912805584910845, 'bidirectional': False, 'lr': 0.0023623778045110174, 'weight_decay': 1.4032869729656879e-08}. Best is trial 6 with value: 0.8944444444444445.\n",
      "[I 2025-11-04 11:34:47,741] Trial 27 pruned. \n",
      "[I 2025-11-04 11:34:50,274] Trial 28 pruned. \n",
      "[I 2025-11-04 11:34:50,853] Trial 29 pruned. \n",
      "[I 2025-11-04 11:34:51,536] Trial 30 pruned. \n",
      "[I 2025-11-04 11:34:51,935] Trial 31 pruned. \n",
      "[I 2025-11-04 11:34:53,092] Trial 32 pruned. \n",
      "[I 2025-11-04 11:34:54,711] Trial 33 pruned. \n",
      "[I 2025-11-04 11:34:55,086] Trial 34 pruned. \n",
      "[I 2025-11-04 11:35:31,733] Trial 35 finished with value: 0.9 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.11159078185167515, 'bidirectional': True, 'lr': 0.0016719911260666689, 'weight_decay': 1.242881605708831e-10}. Best is trial 35 with value: 0.9.\n",
      "[I 2025-11-04 11:35:32,436] Trial 36 pruned. \n",
      "[I 2025-11-04 11:35:35,473] Trial 37 pruned. \n",
      "[I 2025-11-04 11:35:36,227] Trial 38 pruned. \n",
      "[I 2025-11-04 11:35:36,986] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado: 0.9\n",
      "Mejores hiperparámetros: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.11159078185167515, 'bidirectional': True, 'lr': 0.0016719911260666689, 'weight_decay': 1.242881605708831e-10}\n",
      "Epoch 001 | Val Acc: 0.6000\n",
      "Epoch 002 | Val Acc: 0.7444\n",
      "Epoch 003 | Val Acc: 0.7778\n",
      "Epoch 004 | Val Acc: 0.7444\n",
      "Epoch 005 | Val Acc: 0.8222\n",
      "Epoch 006 | Val Acc: 0.7389\n",
      "Epoch 007 | Val Acc: 0.6889\n",
      "Epoch 008 | Val Acc: 0.8056\n",
      "Epoch 009 | Val Acc: 0.8000\n",
      "Epoch 010 | Val Acc: 0.7222\n",
      "Epoch 011 | Val Acc: 0.8389\n",
      "Epoch 012 | Val Acc: 0.8111\n",
      "Epoch 013 | Val Acc: 0.8556\n",
      "Epoch 014 | Val Acc: 0.8111\n",
      "Epoch 015 | Val Acc: 0.8556\n",
      "Epoch 016 | Val Acc: 0.8278\n",
      "Epoch 017 | Val Acc: 0.8056\n",
      "Epoch 018 | Val Acc: 0.8444\n",
      "Epoch 019 | Val Acc: 0.7833\n",
      "Epoch 020 | Val Acc: 0.8278\n",
      "Epoch 021 | Val Acc: 0.7611\n",
      "Epoch 022 | Val Acc: 0.8000\n",
      "Epoch 023 | Val Acc: 0.8333\n",
      "Epoch 024 | Val Acc: 0.8778\n",
      "Epoch 025 | Val Acc: 0.8500\n",
      "Epoch 026 | Val Acc: 0.8722\n",
      "Epoch 027 | Val Acc: 0.8444\n",
      "Epoch 028 | Val Acc: 0.8389\n",
      "Epoch 029 | Val Acc: 0.8278\n",
      "Epoch 030 | Val Acc: 0.8222\n",
      "Epoch 031 | Val Acc: 0.8056\n",
      "Epoch 032 | Val Acc: 0.8667\n",
      "Epoch 033 | Val Acc: 0.8611\n",
      "Epoch 034 | Val Acc: 0.8667\n",
      "Epoch 035 | Val Acc: 0.7944\n",
      "Epoch 036 | Val Acc: 0.8611\n",
      "Epoch 037 | Val Acc: 0.8611\n",
      "Epoch 038 | Val Acc: 0.8556\n",
      "Epoch 039 | Val Acc: 0.8389\n",
      "Epoch 040 | Val Acc: 0.8611\n",
      "Epoch 041 | Val Acc: 0.8500\n",
      "Epoch 042 | Val Acc: 0.8333\n",
      "Epoch 043 | Val Acc: 0.8778\n",
      "Epoch 044 | Val Acc: 0.8611\n",
      "Epoch 045 | Val Acc: 0.8889\n",
      "Epoch 046 | Val Acc: 0.8500\n",
      "Epoch 047 | Val Acc: 0.8722\n",
      "Epoch 048 | Val Acc: 0.8944\n",
      "Epoch 049 | Val Acc: 0.8667\n",
      "Epoch 050 | Val Acc: 0.8611\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study_lstm = optimize_lstm(train_loader_seq, val_loader_seq, n_trials=40, max_epochs=50)\n",
    "    print(\"Mejor resultado:\", study_lstm.best_value)\n",
    "    print(\"Mejores hiperparámetros:\", study_lstm.best_params)\n",
    "\n",
    "    # =============================================================================\n",
    "    # [9] Reentrenar el mejor modelo de forma 100% reproducible\n",
    "    # =============================================================================\n",
    "    best = study_lstm.best_params\n",
    "    set_seed(42)\n",
    "\n",
    "    sample_x, _ = next(iter(train_loader_seq))\n",
    "    input_size = sample_x.shape[-1]\n",
    "\n",
    "    model = LSTMClassifier(\n",
    "        input_size=input_size,\n",
    "        hidden_size=best[\"hidden_size\"],\n",
    "        num_layers=best[\"num_layers\"],\n",
    "        dropout=best[\"dropout\"],\n",
    "        num_classes=4,\n",
    "        bidirectional=best[\"bidirectional\"]\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=best[\"lr\"], weight_decay=best[\"weight_decay\"])\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader_seq:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader_seq:\n",
    "                xb = xb.to(device)\n",
    "                preds = model(xb).argmax(dim=1)\n",
    "                y_true.extend(yb.numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "        val_acc = metrics_from_preds(y_true, y_pred)[\"accuracy\"]\n",
    "        print(f\"Epoch {epoch+1:03d} | Val Acc: {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
