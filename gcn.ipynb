{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41868ed-50f1-451d-8a9e-de339562f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import SequentialSampler, SubsetRandomSampler\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "\n",
    "import optuna\n",
    "from metrics import metrics_from_preds\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaaedc7-1beb-466d-b2f3-0b3ee4c02f9c",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a8842c-5f2b-4476-a2b8-c42c3e8262f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Para secuenciales\\ntrain_loader_seq = DataLoader(VideoDataset(vids_training, labels_training), batch_size=32, shuffle=False)\\nval_loader_seq   = DataLoader(VideoDataset(vids_val, labels_val), batch_size=32, shuffle=False)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Para secuenciales\n",
    "train_loader_seq = DataLoader(VideoDataset(vids_training, labels_training), batch_size=32, shuffle=False)\n",
    "val_loader_seq   = DataLoader(VideoDataset(vids_val, labels_val), batch_size=32, shuffle=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac58d429-b25a-4d48-85ae-9e187efd4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    SEED = seed\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Controla el hash aleatorio de Python\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f74ce88-c202-4b6c-b05c-0e8f1cd0ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483c2a4f-f4bb-41ab-bdd8-32697054d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(\"Usando dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe0935f-e427-42a0-a2bf-96d72fbc2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_training, labels_training, vids_val, labels_val, vids_test, labels_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c016f6-7083-4e78-8430-0f85ff489251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(frames, label):\n",
    "    \"\"\"\n",
    "    Convierte un video (16 x 258) en un grafo:\n",
    "    - 16 nodos (uno por frame).\n",
    "    - Cada nodo con 258 features.\n",
    "    - Aristas entre frames consecutivos.\n",
    "    \"\"\"\n",
    "    x = torch.tensor(frames, dtype=torch.float32)  # (16, 258)\n",
    "\n",
    "    # Conexiones secuenciales (cadena temporal)\n",
    "    edge_index = []\n",
    "    for i in range(len(frames) - 1):\n",
    "        edge_index.append([i, i+1])\n",
    "        edge_index.append([i+1, i])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()  # (2, E)\n",
    "\n",
    "    y = torch.tensor([label], dtype=torch.long)  # etiqueta del grafo\n",
    "    return Data(x=x, edge_index=edge_index, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aca56f6-b830-4f0c-b5ca-b006711ff736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, videos, labels, transform=None):\n",
    "        self.videos = videos\n",
    "        self.labels = labels\n",
    "        super().__init__('.', transform)\n",
    "\n",
    "        self.data_list = [build_graph(v, l) for v, l in zip(videos, labels)]\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50053d9c-0335-4ee9-85d7-c1da21e2fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\polar\\AppData\\Local\\Temp\\ipykernel_9940\\1024000706.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  x = torch.tensor(frames, dtype=torch.float32)  # (16, 258)\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "train_graph_dataset = VideoGraphDataset(vids_training, labels_training)\n",
    "val_graph_dataset   = VideoGraphDataset(vids_val, labels_val)\n",
    "\n",
    "\n",
    "# Permutación fija para tener \"shuffle\" pero reproducible\n",
    "g = torch.Generator().manual_seed(42)\n",
    "perm = torch.randperm(len(train_graph_dataset), generator=g).tolist()\n",
    "train_sampler = SubsetRandomSampler(perm)\n",
    "\n",
    "train_loader_graph = GeoDataLoader(train_graph_dataset, batch_size=32, shuffle=False, num_workers=0, sampler=train_sampler)\n",
    "val_loader_graph   = GeoDataLoader(val_graph_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a6d8e-649c-461d-8641-a220be360a2a",
   "metadata": {},
   "source": [
    "# Modelo GCN (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dcbd6fd-1273-467e-9c7f-9ee9eb4d8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    \"\"\"GCN simple para clasificación de 4 clases.\n",
    "    Entrada: grafo de un frame/video -> salida: logits (B, 4)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=258, hidden_channels=256, num_classes=4, layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Primer bloque\n",
    "        self.layers = nn.ModuleList([GCNConv(in_channels, hidden_channels)])\n",
    "        # Capas intermedias (layers - 1)\n",
    "        for _ in range(layers - 1):\n",
    "            self.layers.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # x: nodos (N, in_channels), edge_index: aristas, batch: asignación de nodos a grafos\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.dropout(x)\n",
    "        x = global_mean_pool(x, batch)  # pooling global\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c36c0a-f916-4945-81fa-9a3440515108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= GCN =========\n",
    "def optimize_gcn(train_loader_graph, val_loader_graph, n_trials=50, max_epochs=80, save_prefix=\"hpo_gcn\"):\n",
    "    set_seed()\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    all_trials = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def objective(trial):\n",
    "        hidden  = trial.suggest_categorical(\"hidden\",[96,128,160,192])\n",
    "        layers  = trial.suggest_int(\"layers\", 2, 5)\n",
    "        drop    = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "        lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "        wd      = trial.suggest_float(\"weight_decay\", 1e-10, 1e-3, log=True)\n",
    "\n",
    "        model = GCNModel(hidden_channels=hidden, layers=layers, dropout=drop).to(device)\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "        opt  = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        best_val = 0.0\n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            for batch in train_loader_graph:\n",
    "                batch = batch.to(device)\n",
    "                opt.zero_grad()\n",
    "                out = model(batch.x, batch.edge_index, batch.batch)\n",
    "                loss = crit(out, batch.y)\n",
    "                loss.backward(); opt.step()\n",
    "            # val\n",
    "            model.eval()\n",
    "            y_true, y_pred = [], []\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader_graph:\n",
    "                    batch = batch.to(device)\n",
    "                    pred = model(batch.x, batch.edge_index, batch.batch).argmax(1)\n",
    "                    y_true.extend(batch.y.cpu().numpy()); y_pred.extend(pred.cpu().numpy())\n",
    "            val_acc = metrics_from_preds(y_true, y_pred)[\"accuracy\"]\n",
    "            if val_acc > best_val: best_val = val_acc\n",
    "            trial.report(val_acc, epoch)\n",
    "            if trial.should_prune(): raise optuna.TrialPruned()\n",
    "\n",
    "        all_trials.append({\"trial\": trial.number, \"params\": trial.params, \"best_val_acc\": best_val})\n",
    "        return best_val\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    with open(f\"{save_prefix}_all.json\",\"w\") as f: json.dump(all_trials,f,indent=2)\n",
    "    with open(f\"{save_prefix}_best.json\",\"w\") as f: json.dump({\"best_params\":study.best_params,\n",
    "                                                               \"best_value\":study.best_value},\n",
    "                                                              f,\n",
    "                                                              indent=2)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55d4503a-677c-4e89-b19a-ba7c8f1385a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 21:06:41,585] A new study created in memory with name: no-name-30066038-5cfb-43ff-a810-87007d568186\n",
      "[I 2025-11-30 21:07:14,552] Trial 0 finished with value: 0.8277777777777777 and parameters: {'hidden': 160, 'layers': 4, 'dropout': 0.011069122058494585, 'lr': 5.782093145482609e-05, 'weight_decay': 1.22648131364617e-08}. Best is trial 0 with value: 0.8277777777777777.\n",
      "[I 2025-11-30 21:07:39,192] Trial 1 finished with value: 0.8444444444444444 and parameters: {'hidden': 96, 'layers': 5, 'dropout': 0.2522414346538968, 'lr': 0.0019201533554539072, 'weight_decay': 2.3791026092081835e-09}. Best is trial 1 with value: 0.8444444444444444.\n",
      "[I 2025-11-30 21:08:07,311] Trial 2 finished with value: 0.8444444444444444 and parameters: {'hidden': 128, 'layers': 3, 'dropout': 0.4988993420902897, 'lr': 0.0023990659904421147, 'weight_decay': 7.798400040517562e-10}. Best is trial 1 with value: 0.8444444444444444.\n",
      "[I 2025-11-30 21:08:40,271] Trial 3 finished with value: 0.8666666666666667 and parameters: {'hidden': 160, 'layers': 3, 'dropout': 0.41262156112848025, 'lr': 7.483303184018257e-05, 'weight_decay': 1.2459398956849304e-07}. Best is trial 3 with value: 0.8666666666666667.\n",
      "[I 2025-11-30 21:11:43,019] Trial 4 finished with value: 0.8611111111111112 and parameters: {'hidden': 128, 'layers': 3, 'dropout': 0.05123371877302069, 'lr': 0.003646900082574579, 'weight_decay': 8.746020673794012e-07}. Best is trial 3 with value: 0.8666666666666667.\n",
      "[I 2025-11-30 21:11:43,387] Trial 5 pruned. \n",
      "[I 2025-11-30 21:11:43,685] Trial 6 pruned. \n",
      "[I 2025-11-30 21:11:43,970] Trial 7 pruned. \n",
      "[I 2025-11-30 21:12:17,765] Trial 8 finished with value: 0.8777777777777778 and parameters: {'hidden': 160, 'layers': 3, 'dropout': 0.3511736117210178, 'lr': 0.0015068092123046973, 'weight_decay': 1.5531107931782493e-06}. Best is trial 8 with value: 0.8777777777777778.\n",
      "[I 2025-11-30 21:12:21,325] Trial 9 pruned. \n",
      "[I 2025-11-30 21:12:21,697] Trial 10 pruned. \n",
      "[I 2025-11-30 21:12:22,052] Trial 11 pruned. \n",
      "[I 2025-11-30 21:12:25,045] Trial 12 pruned. \n",
      "[I 2025-11-30 21:12:25,396] Trial 13 pruned. \n",
      "[I 2025-11-30 21:12:25,814] Trial 14 pruned. \n",
      "[I 2025-11-30 21:12:58,931] Trial 15 finished with value: 0.8666666666666667 and parameters: {'hidden': 160, 'layers': 4, 'dropout': 0.19490276122159764, 'lr': 0.001102839254163386, 'weight_decay': 5.989133322976564e-06}. Best is trial 8 with value: 0.8777777777777778.\n",
      "[I 2025-11-30 21:12:59,314] Trial 16 pruned. \n",
      "[I 2025-11-30 21:12:59,711] Trial 17 pruned. \n",
      "[I 2025-11-30 21:13:00,141] Trial 18 pruned. \n",
      "[I 2025-11-30 21:13:00,514] Trial 19 pruned. \n",
      "[I 2025-11-30 21:13:00,888] Trial 20 pruned. \n",
      "[I 2025-11-30 21:13:36,103] Trial 21 finished with value: 0.8833333333333333 and parameters: {'hidden': 160, 'layers': 4, 'dropout': 0.19636922365934475, 'lr': 0.001313660897462963, 'weight_decay': 1.0182638526745577e-05}. Best is trial 21 with value: 0.8833333333333333.\n",
      "[I 2025-11-30 21:14:12,452] Trial 22 finished with value: 0.8777777777777778 and parameters: {'hidden': 160, 'layers': 5, 'dropout': 0.15147755993201145, 'lr': 0.002774880869006871, 'weight_decay': 9.28096425600237e-08}. Best is trial 21 with value: 0.8833333333333333.\n",
      "[I 2025-11-30 21:14:14,787] Trial 23 pruned. \n",
      "[I 2025-11-30 21:14:17,828] Trial 24 pruned. \n",
      "[I 2025-11-30 21:14:18,169] Trial 25 pruned. \n",
      "[I 2025-11-30 21:14:18,574] Trial 26 pruned. \n",
      "[I 2025-11-30 21:14:18,862] Trial 27 pruned. \n",
      "[I 2025-11-30 21:14:19,110] Trial 28 pruned. \n",
      "[I 2025-11-30 21:14:19,472] Trial 29 pruned. \n",
      "[I 2025-11-30 21:14:19,826] Trial 30 pruned. \n",
      "[I 2025-11-30 21:14:20,154] Trial 31 pruned. \n",
      "[I 2025-11-30 21:14:20,499] Trial 32 pruned. \n",
      "[I 2025-11-30 21:14:20,849] Trial 33 pruned. \n",
      "[I 2025-11-30 21:14:21,199] Trial 34 pruned. \n",
      "[I 2025-11-30 21:14:21,488] Trial 35 pruned. \n",
      "[I 2025-11-30 21:14:21,751] Trial 36 pruned. \n",
      "[I 2025-11-30 21:14:22,030] Trial 37 pruned. \n",
      "[I 2025-11-30 21:14:22,368] Trial 38 pruned. \n",
      "[I 2025-11-30 21:14:22,638] Trial 39 pruned. \n"
     ]
    }
   ],
   "source": [
    "study_gcn = optimize_gcn(train_loader_graph, val_loader_graph, n_trials=40, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ba18852-84e7-46a9-80f5-06d3beee0b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado: 0.8833333333333333\n",
      "Mejores hiperparámetros: {'hidden': 160, 'layers': 4, 'dropout': 0.19636922365934475, 'lr': 0.001313660897462963, 'weight_decay': 1.0182638526745577e-05}\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor resultado:\", study_gcn.best_value)\n",
    "print(\"Mejores hiperparámetros:\", study_gcn.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba603411-7c3c-462f-8ce3-fc51d752f1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando los mejores hiperparámetros desde hpo_gcn_best.json...\n",
      "Hiperparámetros cargados:\n",
      "{'hidden': 160, 'layers': 4, 'dropout': 0.19636922365934475, 'lr': 0.001313660897462963, 'weight_decay': 1.0182638526745577e-05}\n",
      "\n",
      "Entrenando el mejor modelo GCN durante 100 épocas...\n",
      "Epoch [10/100], Loss: 0.6362\n",
      "Epoch [20/100], Loss: 0.3947\n",
      "Epoch [30/100], Loss: 0.3190\n",
      "Epoch [40/100], Loss: 0.2909\n",
      "Epoch [50/100], Loss: 0.2539\n",
      "Epoch [60/100], Loss: 0.1835\n",
      "Epoch [70/100], Loss: 0.1957\n",
      "Epoch [80/100], Loss: 0.1660\n",
      "Epoch [90/100], Loss: 0.1712\n",
      "Epoch [100/100], Loss: 0.1188\n",
      "Entrenamiento completado.\n",
      "\n",
      "--- Métricas del Modelo Final (GCN) ---\n",
      "\n",
      "Resultados en el conjunto de Train:\n",
      "  accuracy: 0.9804\n",
      "  precision_macro: 0.9805\n",
      "  recall_macro: 0.9804\n",
      "  specificity_macro: 0.9935\n",
      "  f1_macro: 0.9804\n",
      "  balanced_accuracy: 0.9804\n",
      "  confusion_matrix: [[253, 0, 1, 1], [0, 246, 7, 2], [0, 3, 252, 0], [2, 3, 1, 249]]\n",
      "\n",
      "Resultados en el conjunto de Validation:\n",
      "  accuracy: 0.8389\n",
      "  precision_macro: 0.8688\n",
      "  recall_macro: 0.8389\n",
      "  specificity_macro: 0.9463\n",
      "  f1_macro: 0.8400\n",
      "  balanced_accuracy: 0.8389\n",
      "  confusion_matrix: [[33, 0, 0, 12], [0, 32, 4, 9], [1, 0, 44, 0], [3, 0, 0, 42]]\n",
      "\n",
      "Modelo guardado exitosamente en: gcn_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from metrics import metrics_from_preds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "# --- Cargar los mejores hiperparámetros ---\n",
    "print(\"Cargando los mejores hiperparámetros desde hpo_gcn_best.json...\")\n",
    "try:\n",
    "    with open(\"hpo_gcn_best.json\", \"r\") as f:\n",
    "        best_hyperparams = json.load(f)[\"best_params\"]\n",
    "    print(\"Hiperparámetros cargados:\")\n",
    "    print(best_hyperparams)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'hpo_gcn_best.json' no fue encontrado.\")\n",
    "    print(\"Por favor, ejecuta primero la celda de optimización para generar este archivo.\")\n",
    "    raise\n",
    "\n",
    "# --- Configurar y entrenar el mejor modelo ---\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instanciar el modelo con los mejores hiperparámetros\n",
    "# Nota: El modelo GCN usa 'hidden_channels', que corresponde a 'hidden' en el JSON.\n",
    "best_model = GCNModel(\n",
    "    hidden_channels=best_hyperparams[\"hidden\"],\n",
    "    layers=best_hyperparams[\"layers\"],\n",
    "    dropout=best_hyperparams[\"dropout\"]\n",
    ").to(device)\n",
    "\n",
    "# Definir criterio de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    best_model.parameters(),\n",
    "    lr=best_hyperparams[\"lr\"],\n",
    "    weight_decay=best_hyperparams[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "epochs = 100  # Usamos las mismas épocas que en la búsqueda de hiperparámetros\n",
    "print(f\"\\nEntrenando el mejor modelo GCN durante {epochs} épocas...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    best_model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader_graph:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = best_model(batch.x, batch.edge_index, batch.batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(train_loader_graph):.4f}\")\n",
    "\n",
    "print(\"Entrenamiento completado.\")\n",
    "\n",
    "# --- Evaluación del modelo y cálculo de métricas ---\n",
    "best_model.eval()\n",
    "all_metrics = {}\n",
    "\n",
    "def evaluate_graph_model(loader, model_name):\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            predictions = best_model(batch.x, batch.edge_index, batch.batch).argmax(1)\n",
    "            y_true.extend(batch.y.cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "    \n",
    "    metrics = metrics_from_preds(y_true, y_pred)\n",
    "    all_metrics[model_name] = metrics\n",
    "\n",
    "print(\"\\n--- Métricas del Modelo Final (GCN) ---\")\n",
    "evaluate_graph_model(train_loader_graph, \"Train\")\n",
    "evaluate_graph_model(val_loader_graph, \"Validation\")\n",
    "\n",
    "for split_name, metrics in all_metrics.items():\n",
    "    print(f\"\\nResultados en el conjunto de {split_name}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {metric_name}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {metric_name}: {value}\")\n",
    "\n",
    "# --- Guardar el modelo entrenado ---\n",
    "model_save_path = \"gcn_best_model.pth\"\n",
    "torch.save(best_model.state_dict(), model_save_path)\n",
    "print(f\"\\nModelo guardado exitosamente en: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79589fb3-1c57-4ff3-aa08-fbb3dc9e45d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
