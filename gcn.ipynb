{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41868ed-50f1-451d-8a9e-de339562f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import SequentialSampler, SubsetRandomSampler\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "\n",
    "import optuna\n",
    "from metrics import metrics_from_preds\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaaedc7-1beb-466d-b2f3-0b3ee4c02f9c",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a8842c-5f2b-4476-a2b8-c42c3e8262f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Para secuenciales\\ntrain_loader_seq = DataLoader(VideoDataset(vids_training, labels_training), batch_size=32, shuffle=False)\\nval_loader_seq   = DataLoader(VideoDataset(vids_val, labels_val), batch_size=32, shuffle=False)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Para secuenciales\n",
    "train_loader_seq = DataLoader(VideoDataset(vids_training, labels_training), batch_size=32, shuffle=False)\n",
    "val_loader_seq   = DataLoader(VideoDataset(vids_val, labels_val), batch_size=32, shuffle=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac58d429-b25a-4d48-85ae-9e187efd4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    SEED = seed\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Controla el hash aleatorio de Python\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f74ce88-c202-4b6c-b05c-0e8f1cd0ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "483c2a4f-f4bb-41ab-bdd8-32697054d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(\"Usando dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe0935f-e427-42a0-a2bf-96d72fbc2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_training, labels_training, vids_val, labels_val, vids_test, labels_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c016f6-7083-4e78-8430-0f85ff489251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(frames, label):\n",
    "    \"\"\"\n",
    "    Convierte un video (16 x 258) en un grafo:\n",
    "    - 16 nodos (uno por frame).\n",
    "    - Cada nodo con 258 features.\n",
    "    - Aristas entre frames consecutivos.\n",
    "    \"\"\"\n",
    "    x = torch.tensor(frames, dtype=torch.float32)  # (16, 258)\n",
    "\n",
    "    # Conexiones secuenciales (cadena temporal)\n",
    "    edge_index = []\n",
    "    for i in range(len(frames) - 1):\n",
    "        edge_index.append([i, i+1])\n",
    "        edge_index.append([i+1, i])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()  # (2, E)\n",
    "\n",
    "    y = torch.tensor([label], dtype=torch.long)  # etiqueta del grafo\n",
    "    return Data(x=x, edge_index=edge_index, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aca56f6-b830-4f0c-b5ca-b006711ff736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, videos, labels, transform=None):\n",
    "        self.videos = videos\n",
    "        self.labels = labels\n",
    "        super().__init__('.', transform)\n",
    "\n",
    "        self.data_list = [build_graph(v, l) for v, l in zip(videos, labels)]\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50053d9c-0335-4ee9-85d7-c1da21e2fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37810/1024000706.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
      "  x = torch.tensor(frames, dtype=torch.float32)  # (16, 258)\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "train_graph_dataset = VideoGraphDataset(vids_training, labels_training)\n",
    "val_graph_dataset   = VideoGraphDataset(vids_val, labels_val)\n",
    "\n",
    "\n",
    "# Permutaci칩n fija para tener \"shuffle\" pero reproducible\n",
    "g = torch.Generator().manual_seed(42)\n",
    "perm = torch.randperm(len(train_graph_dataset), generator=g).tolist()\n",
    "train_sampler = SubsetRandomSampler(perm)\n",
    "\n",
    "train_loader_graph = GeoDataLoader(train_graph_dataset, batch_size=32, shuffle=False, num_workers=0, sampler=train_sampler)\n",
    "val_loader_graph   = GeoDataLoader(val_graph_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a6d8e-649c-461d-8641-a220be360a2a",
   "metadata": {},
   "source": [
    "# Modelo GCN (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dcbd6fd-1273-467e-9c7f-9ee9eb4d8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    \"\"\"GCN simple para clasificaci칩n de 4 clases.\n",
    "    Entrada: grafo de un frame/video -> salida: logits (B, 4)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=258, hidden_channels=256, num_classes=4, layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Primer bloque\n",
    "        self.layers = nn.ModuleList([GCNConv(in_channels, hidden_channels)])\n",
    "        # Capas intermedias (layers - 1)\n",
    "        for _ in range(layers - 1):\n",
    "            self.layers.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # x: nodos (N, in_channels), edge_index: aristas, batch: asignaci칩n de nodos a grafos\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.dropout(x)\n",
    "        x = global_mean_pool(x, batch)  # pooling global\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9c36c0a-f916-4945-81fa-9a3440515108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= GCN =========\n",
    "def optimize_gcn(train_loader_graph, val_loader_graph, n_trials=50, max_epochs=80, save_prefix=\"hpo_gcn\"):\n",
    "    set_seed()\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    all_trials = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def objective(trial):\n",
    "        hidden  = trial.suggest_categorical(\"hidden\",[96,128,160,192])\n",
    "        layers  = trial.suggest_int(\"layers\", 2, 5)\n",
    "        drop    = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "        lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "        wd      = trial.suggest_float(\"weight_decay\", 1e-10, 1e-3, log=True)\n",
    "\n",
    "        model = GCNModel(hidden_channels=hidden, layers=layers, dropout=drop).to(device)\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "        opt  = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        best_val = 0.0\n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            for batch in train_loader_graph:\n",
    "                batch = batch.to(device)\n",
    "                opt.zero_grad()\n",
    "                out = model(batch.x, batch.edge_index, batch.batch)\n",
    "                loss = crit(out, batch.y)\n",
    "                loss.backward(); opt.step()\n",
    "            # val\n",
    "            model.eval()\n",
    "            y_true, y_pred = [], []\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader_graph:\n",
    "                    batch = batch.to(device)\n",
    "                    pred = model(batch.x, batch.edge_index, batch.batch).argmax(1)\n",
    "                    y_true.extend(batch.y.cpu().numpy()); y_pred.extend(pred.cpu().numpy())\n",
    "            val_acc = metrics_from_preds(y_true, y_pred)[\"accuracy\"]\n",
    "            if val_acc > best_val: best_val = val_acc\n",
    "            trial.report(val_acc, epoch)\n",
    "            if trial.should_prune(): raise optuna.TrialPruned()\n",
    "\n",
    "        all_trials.append({\"trial\": trial.number, \"params\": trial.params, \"best_val_acc\": best_val})\n",
    "        return best_val\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    with open(f\"{save_prefix}_all.json\",\"w\") as f: json.dump(all_trials,f,indent=2)\n",
    "    with open(f\"{save_prefix}_best.json\",\"w\") as f: json.dump({\"best_params\":study.best_params,\n",
    "                                                               \"best_value\":study.best_value},\n",
    "                                                              f,\n",
    "                                                              indent=2)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55d4503a-677c-4e89-b19a-ba7c8f1385a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-26 21:41:05,547] A new study created in memory with name: no-name-a3224ffa-8cfc-4206-a2d8-c471a8a5d8a3\n",
      "[I 2025-10-26 21:41:32,395] Trial 0 finished with value: 0.8555555555555555 and parameters: {'hidden': 160, 'layers': 3, 'dropout': 0.282559779642901, 'lr': 0.0004939871586762675, 'weight_decay': 1.6168342504508736e-06}. Best is trial 0 with value: 0.8555555555555555.\n",
      "[I 2025-10-26 21:41:54,482] Trial 1 finished with value: 0.8555555555555555 and parameters: {'hidden': 96, 'layers': 3, 'dropout': 0.050677846187594355, 'lr': 8.677690387452583e-05, 'weight_decay': 2.7364999437208665e-08}. Best is trial 0 with value: 0.8555555555555555.\n",
      "[I 2025-10-26 21:42:26,596] Trial 2 finished with value: 0.8944444444444445 and parameters: {'hidden': 192, 'layers': 4, 'dropout': 0.4197928569413311, 'lr': 0.0017240556232222808, 'weight_decay': 7.909224199438224e-05}. Best is trial 2 with value: 0.8944444444444445.\n"
     ]
    }
   ],
   "source": [
    "study_gcn = optimize_gcn(train_loader_graph, val_loader_graph, n_trials=3, max_epochs=100) #n_trials = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba18852-84e7-46a9-80f5-06d3beee0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejor resultado:\", study_gcn.best_value)\n",
    "print(\"Mejores hiperpar치metros:\", study_gcn.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
