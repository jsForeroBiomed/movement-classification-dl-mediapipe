{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b41868ed-50f1-451d-8a9e-de339562f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Dataset\n",
    "\n",
    "import optuna\n",
    "from metrics import metrics_from_preds\n",
    "from preprocess import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04388df3-6195-4ae2-ad27-156f9e71dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5107af-66b0-45f9-b150-9314bd7704f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cpu\")  # para máxima reproducibilidad\n",
    "print(\"Usando dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23471633-6e8a-46e2-a4b4-d59147502c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_training, labels_training, vids_val, labels_val, vids_test, labels_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a4804a-d0c0-4c2e-8ef4-b9ec72eb6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, videos, labels):\n",
    "        self.videos = videos\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(np.array(self.videos[idx]), dtype=torch.float32)  # (T, F)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b635b1-b3a5-4a24-94f7-70f6cd645404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_pad(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    x = torch.stack(xs, dim=0)  # (B, T, F)\n",
    "    y = torch.stack(ys, dim=0)  # (B,)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f088fc73-8203-4ef8-b984-002b72ab5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b384e02-c14d-4a92-8034-76f84efe4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VideoDataset(vids_training, labels_training)\n",
    "val_dataset   = VideoDataset(vids_val, labels_val)\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "perm = torch.randperm(len(train_dataset), generator=g).tolist()\n",
    "train_sampler = SubsetRandomSampler(perm)\n",
    "\n",
    "train_loader_seq = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=False, sampler=train_sampler,\n",
    "    num_workers=0, collate_fn=collate_pad\n",
    ")\n",
    "val_loader_seq = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False,\n",
    "    num_workers=0, collate_fn=collate_pad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba5cb3ff-50ea-4c38-acca-4a66447a15ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Clasificador secuencial basado en LSTM.\n",
    "       Entrada:  (B, T, F)\n",
    "       LSTM:     salida (B, T, hidden)\n",
    "       Pooling:  último paso temporal\n",
    "       Salida:   (B, num_classes)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=258, hidden_size=128, num_layers=2, dropout=0.1, num_classes=4, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        out_dim = hidden_size * (2 if bidirectional else 1)\n",
    "        self.fc = nn.Linear(out_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):  # x: (B, T, F)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # último paso temporal\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c790f33e-2ee3-4b70-8370-996cba26f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_lstm(train_loader_seq, val_loader_seq, n_trials=10, max_epochs=50, save_prefix=\"hpo_lstm\"):\n",
    "    set_seed(42)\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler,\n",
    "                                pruner=optuna.pruners.MedianPruner())\n",
    "    all_trials = []\n",
    "\n",
    "    sample_x, _ = next(iter(train_loader_seq))\n",
    "    input_size = sample_x.shape[-1]\n",
    "\n",
    "    def objective(trial):\n",
    "        hidden  = trial.suggest_categorical(\"hidden_size\", [64, 96, 128, 160, 192])\n",
    "        layers  = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "        bi      = trial.suggest_categorical(\"bidirectional\", [False, True])\n",
    "        lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "        wd      = trial.suggest_float(\"weight_decay\", 1e-10, 1e-3, log=True)\n",
    "\n",
    "        model = LSTMClassifier(\n",
    "            input_size=input_size, hidden_size=hidden, num_layers=layers,\n",
    "            dropout=dropout, num_classes=4, bidirectional=bi\n",
    "        ).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        best_val = 0.0\n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            for xb, yb in train_loader_seq:\n",
    "                xb = xb.to(device); yb = yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            y_true, y_pred = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader_seq:\n",
    "                    xb = xb.to(device)\n",
    "                    preds = model(xb).argmax(dim=1)\n",
    "                    y_true.extend(yb.numpy())\n",
    "                    y_pred.extend(preds.cpu().numpy())\n",
    "            val_acc = metrics_from_preds(y_true, y_pred)[\"accuracy\"]\n",
    "\n",
    "            if val_acc > best_val:\n",
    "                best_val = val_acc\n",
    "\n",
    "            trial.report(val_acc, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "        all_trials.append({\"trial\": trial.number, \"params\": trial.params, \"best_val_acc\": best_val})\n",
    "        return best_val\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    with open(f\"{save_prefix}_all.json\", \"w\") as f:\n",
    "        json.dump(all_trials, f, indent=2)\n",
    "    with open(f\"{save_prefix}_best.json\", \"w\") as f:\n",
    "        json.dump({\"best_params\": study.best_params, \"best_value\": study.best_value}, f, indent=2)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017021bb-b645-440f-a087-e28511e4cd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 21:59:09,475] A new study created in memory with name: no-name-b4ef4139-9d1e-42ba-ada2-ec0ece6d0f10\n",
      "[I 2025-11-30 21:59:41,629] Trial 0 finished with value: 0.8611111111111112 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.02904180608409973, 'bidirectional': False, 'lr': 0.0013035123791853842, 'weight_decay': 1.3934502251337584e-10}. Best is trial 0 with value: 0.8611111111111112.\n",
      "[I 2025-11-30 22:00:19,922] Trial 1 finished with value: 0.85 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2623782158161189, 'bidirectional': False, 'lr': 0.0008369042894376068, 'weight_decay': 9.472334467618544e-10}. Best is trial 0 with value: 0.8611111111111112.\n",
      "[I 2025-11-30 22:04:58,746] Trial 2 finished with value: 0.8611111111111112 and parameters: {'hidden_size': 160, 'num_layers': 3, 'dropout': 0.29620728443102123, 'bidirectional': True, 'lr': 0.0001096524277832185, 'weight_decay': 2.853390105240223e-10}. Best is trial 0 with value: 0.8611111111111112.\n",
      "[I 2025-11-30 22:06:46,845] Trial 3 finished with value: 0.8611111111111112 and parameters: {'hidden_size': 96, 'num_layers': 3, 'dropout': 0.22007624686980065, 'bidirectional': True, 'lr': 5.8579686961535335e-05, 'weight_decay': 0.0002318690670290197}. Best is trial 0 with value: 0.8611111111111112.\n",
      "[I 2025-11-30 22:07:26,524] Trial 4 finished with value: 0.8666666666666667 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.4847923138822793, 'bidirectional': True, 'lr': 0.0030805247696904818, 'weight_decay': 1.5321449415450716e-06}. Best is trial 4 with value: 0.8666666666666667.\n",
      "[I 2025-11-30 22:07:27,013] Trial 5 pruned. \n",
      "[I 2025-11-30 22:07:59,596] Trial 6 finished with value: 0.8777777777777778 and parameters: {'hidden_size': 160, 'num_layers': 1, 'dropout': 0.0027610585618011996, 'bidirectional': False, 'lr': 0.001435437674097734, 'weight_decay': 2.5054885755573557e-05}. Best is trial 6 with value: 0.8777777777777778.\n",
      "[I 2025-11-30 22:08:02,535] Trial 7 pruned. \n",
      "[I 2025-11-30 22:08:04,084] Trial 8 pruned. \n",
      "[I 2025-11-30 22:08:08,610] Trial 9 pruned. \n",
      "[I 2025-11-30 22:08:09,415] Trial 10 pruned. \n",
      "[I 2025-11-30 22:08:09,882] Trial 11 pruned. \n",
      "[I 2025-11-30 22:08:10,543] Trial 12 pruned. \n",
      "[I 2025-11-30 22:08:11,552] Trial 13 pruned. \n",
      "[I 2025-11-30 22:08:15,224] Trial 14 pruned. \n",
      "[I 2025-11-30 22:08:19,904] Trial 15 pruned. \n",
      "[I 2025-11-30 22:08:20,340] Trial 16 pruned. \n",
      "[I 2025-11-30 22:10:40,582] Trial 17 finished with value: 0.8666666666666667 and parameters: {'hidden_size': 160, 'num_layers': 2, 'dropout': 0.31122173984401474, 'bidirectional': True, 'lr': 0.0003293390194243909, 'weight_decay': 9.629032699554377e-07}. Best is trial 6 with value: 0.8777777777777778.\n",
      "[I 2025-11-30 22:10:41,364] Trial 18 pruned. \n",
      "[I 2025-11-30 22:10:42,283] Trial 19 pruned. \n",
      "[I 2025-11-30 22:10:45,343] Trial 20 pruned. \n",
      "[I 2025-11-30 22:10:48,140] Trial 21 pruned. \n",
      "[I 2025-11-30 22:10:50,933] Trial 22 pruned. \n",
      "[I 2025-11-30 22:10:52,182] Trial 23 pruned. \n",
      "[I 2025-11-30 22:10:56,769] Trial 24 pruned. \n",
      "[I 2025-11-30 22:10:58,276] Trial 25 pruned. \n",
      "[I 2025-11-30 22:10:58,945] Trial 26 pruned. \n",
      "[I 2025-11-30 22:11:00,381] Trial 27 pruned. \n",
      "[I 2025-11-30 22:11:02,435] Trial 28 pruned. \n",
      "[I 2025-11-30 22:11:03,728] Trial 29 pruned. \n",
      "[I 2025-11-30 22:11:05,083] Trial 30 pruned. \n",
      "[I 2025-11-30 22:11:05,520] Trial 31 pruned. \n",
      "[I 2025-11-30 22:11:07,015] Trial 32 pruned. \n",
      "[I 2025-11-30 22:11:07,952] Trial 33 pruned. \n",
      "[I 2025-11-30 22:11:08,853] Trial 34 pruned. \n",
      "[I 2025-11-30 22:11:33,853] Trial 35 finished with value: 0.8611111111111112 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.17888021795170964, 'bidirectional': False, 'lr': 0.0009532769194200945, 'weight_decay': 4.000072017057411e-07}. Best is trial 6 with value: 0.8777777777777778.\n",
      "[I 2025-11-30 22:11:34,649] Trial 36 pruned. \n",
      "[I 2025-11-30 22:11:36,315] Trial 37 pruned. \n",
      "[I 2025-11-30 22:17:26,673] Trial 38 finished with value: 0.85 and parameters: {'hidden_size': 192, 'num_layers': 3, 'dropout': 0.11408077261650389, 'bidirectional': True, 'lr': 0.0002962349392645745, 'weight_decay': 4.855513661289156e-06}. Best is trial 6 with value: 0.8777777777777778.\n",
      "[I 2025-11-30 22:17:27,550] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado: 0.8777777777777778\n",
      "Mejores hiperparámetros: {'hidden_size': 160, 'num_layers': 1, 'dropout': 0.0027610585618011996, 'bidirectional': False, 'lr': 0.001435437674097734, 'weight_decay': 2.5054885755573557e-05}\n",
      "Epoch 001 | Val Acc: 0.6833\n",
      "Epoch 002 | Val Acc: 0.6889\n",
      "Epoch 003 | Val Acc: 0.7111\n",
      "Epoch 004 | Val Acc: 0.7444\n",
      "Epoch 005 | Val Acc: 0.8222\n",
      "Epoch 006 | Val Acc: 0.7778\n",
      "Epoch 007 | Val Acc: 0.7778\n",
      "Epoch 008 | Val Acc: 0.7944\n",
      "Epoch 009 | Val Acc: 0.6889\n",
      "Epoch 010 | Val Acc: 0.8056\n",
      "Epoch 011 | Val Acc: 0.8222\n",
      "Epoch 012 | Val Acc: 0.7833\n",
      "Epoch 013 | Val Acc: 0.8111\n",
      "Epoch 014 | Val Acc: 0.7111\n",
      "Epoch 015 | Val Acc: 0.8167\n",
      "Epoch 016 | Val Acc: 0.7889\n",
      "Epoch 017 | Val Acc: 0.7167\n",
      "Epoch 018 | Val Acc: 0.8167\n",
      "Epoch 019 | Val Acc: 0.7889\n",
      "Epoch 020 | Val Acc: 0.7944\n",
      "Epoch 021 | Val Acc: 0.8167\n",
      "Epoch 022 | Val Acc: 0.7778\n",
      "Epoch 023 | Val Acc: 0.7944\n",
      "Epoch 024 | Val Acc: 0.7778\n",
      "Epoch 025 | Val Acc: 0.7944\n",
      "Epoch 026 | Val Acc: 0.8222\n",
      "Epoch 027 | Val Acc: 0.7833\n",
      "Epoch 028 | Val Acc: 0.7500\n",
      "Epoch 029 | Val Acc: 0.8389\n",
      "Epoch 030 | Val Acc: 0.8222\n",
      "Epoch 031 | Val Acc: 0.8333\n",
      "Epoch 032 | Val Acc: 0.7611\n",
      "Epoch 033 | Val Acc: 0.8333\n",
      "Epoch 034 | Val Acc: 0.8444\n",
      "Epoch 035 | Val Acc: 0.7667\n",
      "Epoch 036 | Val Acc: 0.8500\n",
      "Epoch 037 | Val Acc: 0.7833\n",
      "Epoch 038 | Val Acc: 0.8889\n",
      "Epoch 039 | Val Acc: 0.8111\n",
      "Epoch 040 | Val Acc: 0.7944\n",
      "Epoch 041 | Val Acc: 0.8833\n",
      "Epoch 042 | Val Acc: 0.8167\n",
      "Epoch 043 | Val Acc: 0.8500\n",
      "Epoch 044 | Val Acc: 0.8000\n",
      "Epoch 045 | Val Acc: 0.8111\n",
      "Epoch 046 | Val Acc: 0.7889\n",
      "Epoch 047 | Val Acc: 0.8667\n",
      "Epoch 048 | Val Acc: 0.8111\n",
      "Epoch 049 | Val Acc: 0.8500\n",
      "Epoch 050 | Val Acc: 0.8667\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study_lstm = optimize_lstm(train_loader_seq, val_loader_seq, n_trials=40, max_epochs=50)\n",
    "    print(\"Mejor resultado:\", study_lstm.best_value)\n",
    "    print(\"Mejores hiperparámetros:\", study_lstm.best_params)\n",
    "\n",
    "    # =============================================================================\n",
    "    # [9] Reentrenar el mejor modelo de forma 100% reproducible\n",
    "    # =============================================================================\n",
    "    best = study_lstm.best_params\n",
    "    set_seed(42)\n",
    "\n",
    "    sample_x, _ = next(iter(train_loader_seq))\n",
    "    input_size = sample_x.shape[-1]\n",
    "\n",
    "    model = LSTMClassifier(\n",
    "        input_size=input_size,\n",
    "        hidden_size=best[\"hidden_size\"],\n",
    "        num_layers=best[\"num_layers\"],\n",
    "        dropout=best[\"dropout\"],\n",
    "        num_classes=4,\n",
    "        bidirectional=best[\"bidirectional\"]\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=best[\"lr\"], weight_decay=best[\"weight_decay\"])\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader_seq:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader_seq:\n",
    "                xb = xb.to(device)\n",
    "                preds = model(xb).argmax(dim=1)\n",
    "                y_true.extend(yb.numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "        val_acc = metrics_from_preds(y_true, y_pred)[\"accuracy\"]\n",
    "        print(f\"Epoch {epoch+1:03d} | Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2789a8a9-42ef-4144-81af-3659d6ba0926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando los mejores hiperparámetros desde hpo_lstm_best.json...\n",
      "Hiperparámetros cargados:\n",
      "{'hidden_size': 160, 'num_layers': 1, 'dropout': 0.0027610585618011996, 'bidirectional': False, 'lr': 0.001435437674097734, 'weight_decay': 2.5054885755573557e-05}\n",
      "\n",
      "Entrenando el mejor modelo LSTM durante 50 épocas...\n",
      "Epoch [10/50], Loss: 0.4386\n",
      "Epoch [20/50], Loss: 0.2168\n",
      "Epoch [30/50], Loss: 0.0894\n",
      "Epoch [40/50], Loss: 0.0307\n",
      "Epoch [50/50], Loss: 0.0146\n",
      "Entrenamiento completado.\n",
      "\n",
      "--- Métricas del Modelo Final (LSTM) ---\n",
      "\n",
      "Resultados en el conjunto de Train:\n",
      "  accuracy: 0.9980\n",
      "  precision_macro: 0.9980\n",
      "  recall_macro: 0.9980\n",
      "  specificity_macro: 0.9993\n",
      "  f1_macro: 0.9980\n",
      "  balanced_accuracy: 0.9980\n",
      "  confusion_matrix: [[254, 0, 0, 1], [0, 254, 1, 0], [0, 0, 255, 0], [0, 0, 0, 255]]\n",
      "\n",
      "Resultados en el conjunto de Validation:\n",
      "  accuracy: 0.7833\n",
      "  precision_macro: 0.8199\n",
      "  recall_macro: 0.7833\n",
      "  specificity_macro: 0.9278\n",
      "  f1_macro: 0.7768\n",
      "  balanced_accuracy: 0.7833\n",
      "  confusion_matrix: [[24, 3, 12, 6], [0, 33, 7, 5], [1, 0, 44, 0], [0, 2, 3, 40]]\n",
      "\n",
      "Modelo guardado exitosamente en: lstm_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from metrics import metrics_from_preds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# --- Cargar los mejores hiperparámetros ---\n",
    "print(\"Cargando los mejores hiperparámetros desde hpo_lstm_best.json...\")\n",
    "try:\n",
    "    with open(\"hpo_lstm_best.json\", \"r\") as f:\n",
    "        best_hyperparams = json.load(f)[\"best_params\"]\n",
    "    print(\"Hiperparámetros cargados:\")\n",
    "    print(best_hyperparams)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'hpo_lstm_best.json' no fue encontrado.\")\n",
    "    print(\"Por favor, ejecuta primero la celda de optimización para generar este archivo.\")\n",
    "    raise\n",
    "\n",
    "# --- Configurar y entrenar el mejor modelo ---\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Es necesario determinar el número de features de entrada desde los datos\n",
    "try:\n",
    "    sample_x, _ = next(iter(train_loader_seq))\n",
    "    input_size = sample_x.shape[-1]\n",
    "except NameError:\n",
    "    print(\"Error: 'train_loader_seq' no está definido. Asegúrate de haber ejecutado las celdas de preparación de datos.\")\n",
    "    raise\n",
    "\n",
    "# Instanciar el modelo con los mejores hiperparámetros\n",
    "best_model = LSTMClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=best_hyperparams[\"hidden_size\"],\n",
    "    num_layers=best_hyperparams[\"num_layers\"],\n",
    "    dropout=best_hyperparams[\"dropout\"],\n",
    "    bidirectional=best_hyperparams[\"bidirectional\"],\n",
    "    num_classes=4\n",
    ").to(device)\n",
    "\n",
    "# Definir criterio de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    best_model.parameters(),\n",
    "    lr=best_hyperparams[\"lr\"],\n",
    "    weight_decay=best_hyperparams[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "epochs = 50  # Usamos las mismas épocas que en la búsqueda de hiperparámetros\n",
    "print(f\"\\nEntrenando el mejor modelo LSTM durante {epochs} épocas...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    best_model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader_seq:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = best_model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(train_loader_seq):.4f}\")\n",
    "\n",
    "print(\"Entrenamiento completado.\")\n",
    "\n",
    "# --- Evaluación del modelo y cálculo de métricas ---\n",
    "best_model.eval()\n",
    "all_metrics = {}\n",
    "\n",
    "def evaluate_seq_model(loader, model_name):\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            predictions = best_model(xb).argmax(dim=1)\n",
    "            y_true.extend(yb.numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "    \n",
    "    metrics = metrics_from_preds(y_true, y_pred)\n",
    "    all_metrics[model_name] = metrics\n",
    "\n",
    "print(\"\\n--- Métricas del Modelo Final (LSTM) ---\")\n",
    "evaluate_seq_model(train_loader_seq, \"Train\")\n",
    "evaluate_seq_model(val_loader_seq, \"Validation\")\n",
    "\n",
    "for split_name, metrics in all_metrics.items():\n",
    "    print(f\"\\nResultados en el conjunto de {split_name}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {metric_name}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {metric_name}: {value}\")\n",
    "\n",
    "# --- Guardar el modelo entrenado ---\n",
    "model_save_path = \"lstm_best_model.pth\"\n",
    "torch.save(best_model.state_dict(), model_save_path)\n",
    "print(f\"\\nModelo guardado exitosamente en: {model_save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
