{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41868ed-50f1-451d-8a9e-de339562f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "\n",
    "import optuna\n",
    "from metrics import metrics_from_preds\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaaedc7-1beb-466d-b2f3-0b3ee4c02f9c",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac58d429-b25a-4d48-85ae-9e187efd4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    SEED = seed\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f74ce88-c202-4b6c-b05c-0e8f1cd0ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "483c2a4f-f4bb-41ab-bdd8-32697054d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efe0935f-e427-42a0-a2bf-96d72fbc2ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\A_Investigacion\\post_semillero\\ai_paper_js_gl\\data\n"
     ]
    }
   ],
   "source": [
    "vids_training, labels_training, vids_val, labels_val, vids_test, labels_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64dbffe7-fec1-49f4-a1a7-85a1c83fb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, videos, labels):\n",
    "        self.videos = videos\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(np.array(self.videos[idx]), dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50053d9c-0335-4ee9-85d7-c1da21e2fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "train_dataset = VideoDataset(vids_training, labels_training)\n",
    "val_dataset   = VideoDataset(vids_val, labels_val)\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "perm = torch.randperm(len(train_dataset), generator=g).tolist()\n",
    "train_sampler = SubsetRandomSampler(perm)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=0, sampler=train_sampler)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a6d8e-649c-461d-8641-a220be360a2a",
   "metadata": {},
   "source": [
    "# Modelo Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac1e4bac-038d-443b-9eb0-697132a444a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim=258, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm2(x + ff_out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b855b22-7ba1-42c7-a573-62326bb05efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, in_features=258, num_classes=4, num_heads=4, layers=2, hidden=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(in_features, hidden)\n",
    "        self.layers = nn.ModuleList([\n",
    "            SelfAttentionBlock(embed_dim=hidden, num_heads=num_heads, dropout=dropout) for _ in range(layers)\n",
    "        ])\n",
    "        self.head = nn.Linear(hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x.mean(dim=1)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c099a11-add6-4dc4-a8fe-22d051f555d9",
   "metadata": {},
   "source": [
    "# Optimización de Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9c36c0a-f916-4945-81fa-9a3440515108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_transformer(train_loader, val_loader, n_trials=50, max_epochs=80, save_prefix=\"hpo_transformer\"):\n",
    "    set_seed()\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=optuna.pruners.MedianPruner())\n",
    "    all_trials = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def objective(trial):\n",
    "        hidden  = trial.suggest_categorical(\"hidden\",[96,128,160,192])\n",
    "        layers  = trial.suggest_int(\"layers\", 2, 5)\n",
    "        num_heads = trial.suggest_categorical(\"num_heads\", [2, 4, 8])\n",
    "        drop    = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "        lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "        wd      = trial.suggest_float(\"weight_decay\", 1e-10, 1e-3, log=True)\n",
    "\n",
    "        model = TransformerModel(hidden=hidden, layers=layers, num_heads=num_heads, dropout=drop).to(device)\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "        opt  = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        best_val = 0.0\n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            for X, y in train_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                opt.zero_grad()\n",
    "                out = model(X)\n",
    "                loss = crit(out, y)\n",
    "                loss.backward(); opt.step()\n",
    "            model.eval()\n",
    "            y_true, y_pred = [], []\n",
    "            with torch.no_grad():\n",
    "                for X, y in val_loader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    pred = model(X).argmax(1)\n",
    "                    y_true.extend(y.cpu().numpy()); y_pred.extend(pred.cpu().numpy())\n",
    "            val_acc = metrics_from_preds(y_true, y_pred)[\"accuracy\"]\n",
    "            if val_acc > best_val: best_val = val_acc\n",
    "            trial.report(val_acc, epoch)\n",
    "            if trial.should_prune(): raise optuna.TrialPruned()\n",
    "\n",
    "        all_trials.append({\"trial\": trial.number, \"params\": trial.params, \"best_val_acc\": best_val})\n",
    "        return best_val\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    with open(f\"{save_prefix}_all.json\",\"w\") as f: json.dump(all_trials,f,indent=2)\n",
    "    with open(f\"{save_prefix}_best.json\", \"w\") as f: json.dump({\"best_params\":study.best_params, \"best_value\":study.best_value}, f, indent=2)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55d4503a-677c-4e89-b19a-ba7c8f1385a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 19:41:07,002] A new study created in memory with name: no-name-396d6f8d-7cd9-43cc-9f1e-04a3b3e05389\n",
      "[I 2025-11-30 19:42:32,832] Trial 0 finished with value: 0.9333333333333333 and parameters: {'hidden': 128, 'layers': 2, 'num_heads': 8, 'dropout': 0.3005575058716044, 'lr': 0.0013035123791853842, 'weight_decay': 1.3934502251337584e-10}. Best is trial 0 with value: 0.9333333333333333.\n",
      "[I 2025-11-30 19:43:36,750] Trial 1 finished with value: 0.9277777777777778 and parameters: {'hidden': 96, 'layers': 2, 'num_heads': 4, 'dropout': 0.14561457009902096, 'lr': 0.0008369042894376068, 'weight_decay': 9.472334467618544e-10}. Best is trial 0 with value: 0.9333333333333333.\n",
      "[I 2025-11-30 19:45:21,123] Trial 2 finished with value: 0.9277777777777778 and parameters: {'hidden': 192, 'layers': 2, 'num_heads': 4, 'dropout': 0.3037724259507192, 'lr': 0.0001096524277832185, 'weight_decay': 2.853390105240223e-10}. Best is trial 0 with value: 0.9333333333333333.\n",
      "[I 2025-11-30 19:47:25,322] Trial 3 finished with value: 0.9277777777777778 and parameters: {'hidden': 128, 'layers': 2, 'num_heads': 2, 'dropout': 0.2475884550556351, 'lr': 5.8579686961535335e-05, 'weight_decay': 0.0002318690670290197}. Best is trial 0 with value: 0.9333333333333333.\n",
      "[I 2025-11-30 19:50:44,396] Trial 4 finished with value: 0.25 and parameters: {'hidden': 128, 'layers': 4, 'num_heads': 4, 'dropout': 0.46974947078209456, 'lr': 0.0030805247696904818, 'weight_decay': 1.5321449415450716e-06}. Best is trial 0 with value: 0.9333333333333333.\n",
      "[I 2025-11-30 20:03:28,792] Trial 5 finished with value: 0.9277777777777778 and parameters: {'hidden': 96, 'layers': 3, 'num_heads': 8, 'dropout': 0.17837666334679464, 'lr': 0.00018232197794903611, 'weight_decay': 6.293215187893864e-07}. Best is trial 0 with value: 0.9333333333333333.\n",
      "[I 2025-11-30 20:03:31,600] Trial 6 pruned. \n",
      "[I 2025-11-30 20:03:33,616] Trial 7 pruned. \n",
      "[I 2025-11-30 20:06:01,674] Trial 8 finished with value: 0.95 and parameters: {'hidden': 96, 'layers': 5, 'num_heads': 4, 'dropout': 0.26136641469099703, 'lr': 0.00035813934999486707, 'weight_decay': 1.5063777323554432e-10}. Best is trial 8 with value: 0.95.\n",
      "[I 2025-11-30 20:08:47,421] Trial 9 finished with value: 0.95 and parameters: {'hidden': 160, 'layers': 4, 'num_heads': 2, 'dropout': 0.37777556927152434, 'lr': 0.00014340567410515046, 'weight_decay': 3.4582737549732045e-10}. Best is trial 8 with value: 0.95.\n",
      "[I 2025-11-30 20:10:53,340] Trial 10 finished with value: 0.9222222222222223 and parameters: {'hidden': 96, 'layers': 5, 'num_heads': 4, 'dropout': 0.008980937807409994, 'lr': 0.0003898150920942755, 'weight_decay': 1.6387443765678535e-08}. Best is trial 8 with value: 0.95.\n",
      "[I 2025-11-30 20:10:59,211] Trial 11 pruned. \n",
      "[I 2025-11-30 20:11:03,918] Trial 12 pruned. \n",
      "[I 2025-11-30 20:11:05,217] Trial 13 pruned. \n",
      "[I 2025-11-30 20:11:11,187] Trial 14 pruned. \n",
      "[I 2025-11-30 20:11:13,121] Trial 15 pruned. \n",
      "[I 2025-11-30 20:11:16,200] Trial 16 pruned. \n",
      "[I 2025-11-30 20:11:23,342] Trial 17 pruned. \n",
      "[I 2025-11-30 20:11:25,965] Trial 18 pruned. \n",
      "[I 2025-11-30 20:13:50,495] Trial 19 finished with value: 0.9444444444444444 and parameters: {'hidden': 96, 'layers': 5, 'num_heads': 8, 'dropout': 0.2177343251658946, 'lr': 0.0005567738214044445, 'weight_decay': 5.93800236418028e-10}. Best is trial 8 with value: 0.95.\n",
      "[I 2025-11-30 20:13:54,464] Trial 20 pruned. \n",
      "[I 2025-11-30 20:14:11,814] Trial 21 pruned. \n",
      "[I 2025-11-30 20:14:17,696] Trial 22 pruned. \n",
      "[I 2025-11-30 20:16:42,583] Trial 23 finished with value: 0.95 and parameters: {'hidden': 96, 'layers': 5, 'num_heads': 8, 'dropout': 0.2629269662805934, 'lr': 0.0004077769443944543, 'weight_decay': 2.5677062988088583e-09}. Best is trial 8 with value: 0.95.\n",
      "[I 2025-11-30 20:16:43,764] Trial 24 pruned. \n",
      "[I 2025-11-30 20:20:15,638] Trial 25 finished with value: 0.9444444444444444 and parameters: {'hidden': 160, 'layers': 5, 'num_heads': 8, 'dropout': 0.3499197204649744, 'lr': 0.00017933341917697424, 'weight_decay': 1.7909030444991475e-10}. Best is trial 8 with value: 0.95.\n",
      "[I 2025-11-30 20:20:21,262] Trial 26 pruned. \n",
      "[I 2025-11-30 20:23:19,761] Trial 27 finished with value: 0.9388888888888889 and parameters: {'hidden': 192, 'layers': 4, 'num_heads': 2, 'dropout': 0.25864409079516965, 'lr': 0.00022277444346204315, 'weight_decay': 1.9440339271153755e-07}. Best is trial 8 with value: 0.95.\n",
      "[I 2025-11-30 20:23:23,440] Trial 28 pruned. \n",
      "[I 2025-11-30 20:23:32,300] Trial 29 pruned. \n",
      "[I 2025-11-30 20:23:34,013] Trial 30 pruned. \n",
      "[I 2025-11-30 20:23:35,449] Trial 31 pruned. \n",
      "[I 2025-11-30 20:23:36,840] Trial 32 pruned. \n",
      "[I 2025-11-30 20:23:38,281] Trial 33 pruned. \n",
      "[I 2025-11-30 20:23:39,764] Trial 34 pruned. \n",
      "[I 2025-11-30 20:23:46,393] Trial 35 pruned. \n",
      "[I 2025-11-30 20:26:10,679] Trial 36 finished with value: 0.9388888888888889 and parameters: {'hidden': 128, 'layers': 4, 'num_heads': 8, 'dropout': 0.32471811687252194, 'lr': 0.0002904010797092143, 'weight_decay': 3.9083220191128286e-10}. Best is trial 8 with value: 0.95.\n",
      "[I 2025-11-30 20:26:13,164] Trial 37 pruned. \n",
      "[I 2025-11-30 20:26:15,520] Trial 38 pruned. \n",
      "[I 2025-11-30 20:26:16,446] Trial 39 pruned. \n"
     ]
    }
   ],
   "source": [
    "study_transformer = optimize_transformer(train_loader, val_loader, n_trials=40, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba18852-84e7-46a9-80f5-06d3beee0b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado: 0.95\n",
      "Mejores hiperparámetros: {'hidden': 96, 'layers': 5, 'num_heads': 4, 'dropout': 0.26136641469099703, 'lr': 0.00035813934999486707, 'weight_decay': 1.5063777323554432e-10}\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor resultado:\", study_transformer.best_value)\n",
    "print(\"Mejores hiperparámetros:\", study_transformer.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5abb2ca8-aab7-4c87-b3d0-3bce7a916ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando los mejores hiperparámetros desde hpo_transformer_best.json...\n",
      "Hiperparámetros cargados:\n",
      "{'hidden': 96, 'layers': 5, 'num_heads': 4, 'dropout': 0.26136641469099703, 'lr': 0.00035813934999486707, 'weight_decay': 1.5063777323554432e-10}\n",
      "\n",
      "Entrenando el mejor modelo durante 100 épocas...\n",
      "Epoch [10/100], Loss: 0.4147\n",
      "Epoch [20/100], Loss: 0.1339\n",
      "Epoch [30/100], Loss: 0.0675\n",
      "Epoch [40/100], Loss: 0.3449\n",
      "Epoch [50/100], Loss: 0.0182\n",
      "Epoch [60/100], Loss: 0.0031\n",
      "Epoch [70/100], Loss: 0.1464\n",
      "Epoch [80/100], Loss: 0.0022\n",
      "Epoch [90/100], Loss: 0.0010\n",
      "Epoch [100/100], Loss: 0.0007\n",
      "Entrenamiento completado.\n",
      "\n",
      "--- Métricas del Modelo Final ---\n",
      "\n",
      "Resultados en el conjunto de Train:\n",
      "  accuracy: 1.0000\n",
      "  precision_macro: 1.0000\n",
      "  recall_macro: 1.0000\n",
      "  specificity_macro: 1.0000\n",
      "  f1_macro: 1.0000\n",
      "  balanced_accuracy: 1.0000\n",
      "  confusion_matrix: [[255, 0, 0, 0], [0, 255, 0, 0], [0, 0, 255, 0], [0, 0, 0, 255]]\n",
      "\n",
      "Resultados en el conjunto de Validation:\n",
      "  accuracy: 0.9333\n",
      "  precision_macro: 0.9373\n",
      "  recall_macro: 0.9333\n",
      "  specificity_macro: 0.9778\n",
      "  f1_macro: 0.9306\n",
      "  balanced_accuracy: 0.9333\n",
      "  confusion_matrix: [[44, 1, 0, 0], [1, 34, 5, 5], [0, 0, 45, 0], [0, 0, 0, 45]]\n",
      "\n",
      "Modelo guardado exitosamente en: transformer_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from metrics import metrics_from_preds # Corregido de \"metrics_from_\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# --- Cargar los mejores hiperparámetros ---\n",
    "print(\"Cargando los mejores hiperparámetros desde hpo_transformer_best.json...\")\n",
    "try:\n",
    "    with open(\"hpo_transformer_best.json\", \"r\") as f:\n",
    "        best_hyperparams = json.load(f)[\"best_params\"]\n",
    "    print(\"Hiperparámetros cargados:\")\n",
    "    print(best_hyperparams)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'hpo_transformer_best.json' no fue encontrado.\")\n",
    "    print(\"Por favor, asegúrate de que el archivo exista y contenga los mejores hiperparámetros.\")\n",
    "    # Detener la ejecución si el archivo no existe.\n",
    "    # En un notebook, puedes simplemente no ejecutar las celdas siguientes.\n",
    "    raise\n",
    "\n",
    "# --- Configurar y entrenar el mejor modelo ---\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instanciar el modelo con los mejores hiperparámetros\n",
    "best_model = TransformerModel(\n",
    "    hidden=best_hyperparams[\"hidden\"],\n",
    "    layers=best_hyperparams[\"layers\"],\n",
    "    num_heads=best_hyperparams[\"num_heads\"],\n",
    "    dropout=best_hyperparams[\"dropout\"]\n",
    ").to(device)\n",
    "\n",
    "# Definir criterio de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    best_model.parameters(),\n",
    "    lr=best_hyperparams[\"lr\"],\n",
    "    weight_decay=best_hyperparams[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "epochs = 100  # Usamos 100 épocas como en la búsqueda de hiperparámetros\n",
    "print(f\"\\nEntrenando el mejor modelo durante {epochs} épocas...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    best_model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = best_model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Entrenamiento completado.\")\n",
    "\n",
    "# --- Evaluación del modelo y cálculo de métricas ---\n",
    "best_model.eval()\n",
    "all_metrics = {}\n",
    "\n",
    "# Función para evaluar un dataloader\n",
    "def evaluate_model(loader, model_name):\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            predictions = best_model(X).argmax(1)\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "    \n",
    "    metrics = metrics_from_preds(y_true, y_pred)\n",
    "    all_metrics[model_name] = metrics\n",
    "\n",
    "# Evaluar en conjunto de entrenamiento y validación\n",
    "print(\"\\n--- Métricas del Modelo Final ---\")\n",
    "evaluate_model(train_loader, \"Train\")\n",
    "evaluate_model(val_loader, \"Validation\")\n",
    "\n",
    "# Imprimir métricas de forma legible\n",
    "for split_name, metrics in all_metrics.items():\n",
    "    print(f\"\\nResultados en el conjunto de {split_name}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {metric_name}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {metric_name}: {value}\")\n",
    "\n",
    "# --- Guardar el modelo entrenado ---\n",
    "model_save_path = \"transformer_best_model.pth\"\n",
    "torch.save(best_model.state_dict(), model_save_path)\n",
    "print(f\"\\nModelo guardado exitosamente en: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e960cd-2f61-4539-b3f0-733bc89173d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
